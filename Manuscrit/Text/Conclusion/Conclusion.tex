\documentclass[../../Main_ManuscritThese.tex]{subfiles}

\subfileGlobal{
\renewcommand{\RootDir}[1]{./Text/Chapter4/#1}
}

% For cross referencing
\subfileLocal{
\externaldocument{../../Text/Introduction/build/Introduction}
\externaldocument{../../Text/Chapter2/build/Chapter2}
\externaldocument{../../Text/Chapter3/build/Chapter3}
\externaldocument{../../Text/Chapter4/build/Chapter4}
\externaldocument{../../Text/Chapter5/build/Chapter5}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CHAPTER TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\pagestyle{conclusionStyle}

% \relax

% \begingroup
%% ---- On veut que "conclusion" soit entre les trait au début du chapitre

%% ---- On veut que ce soit le chapitre numéro 3 en notation alphabétique pour avoir un C
% \clearpage
% \setcounter{chapter}{2}
% \renewcommand{\thechapter}{\Alph{chapter}}%
\TitleBtwLines
\chapter*{Conclusion and perspectives}
\phantomsection
\addstarredchapter{Conclusion and perspectives}
\label{chap:Conclusion}
\renewcommand{\thesection}{} % In this thesis, we studied the problem of
% the calibration of a numerical model under uncertainties, by proposing a new criterion based on the regret, relative or additive

\paragraph{Summary}
In~\cref{chap:inverse_problem}, after having detailed common notions
of probabilities and statistical inference, we presented the
calibration problem as an optimisation problem, by introducing an
objective function, which we can see as a \emph{loss} we wish to
minimise. However, due to the presence of the environmental variable
in the study, a plain minimisation of the objective function is not
possible: by taking into account the random nature of the
\emph{nuisance parameters}, the calibration can be seen as a problem
of \emph{optimisation under uncertainties}, and specific methods and
criterion can be defined to treat accordingly this new problem.


Some classical criteria are first introduced
in~\cref{chap:robust_estimators}, leading to Bayesian or frequentist
estimates if we keep an inference framework, or estimates such as the
minimiser of the mean value of the objective function. In this thesis,
we introduce a new estimate based on the regret. Instead of comparing
directly the values of the objective function for different situations
corresponding to different values of the uncertain variable, the
regret allows the modeller to compare the value of the objective with
the best attainable performance given a specific environmental
variable. This allows to put less emphasis on configurations which
already lead to bad performances, and to focus more on salveagable
situations.

Moreover, the user can adjust a parameter in order to reflect either a
risk-adverse behaviour, by favourising a control of the regret with
high probability, or a risk-seeking one, by favourising an estimate
that will yield values of the regret closer to its optimum, albeit
with lower probability.


In general, criteria of robust optimisation require a global
knowledge of the function, since they often involve the evaluation of
expectations and probabilities with respect to $\UU$. In addition to
that, regret-based criteria we introduced depend directly on the
conditional minimum and minimiser. In~\cref{chap:adaptative_design_gp},
we proposed to use Gaussian Processes in order to compute the
quantities associated with regret-based estimators. More precisely, we
proposed a few methods which aim at improving this estimation by
choosing iteratively a new, or a batch of new points to evaluate and
to add to the design.

Finally in~\cref{chap:croco}, we studied an academic problem of
calibration of a coastal model based on CROCO. After having reduced
the input space based on the sediment type at the bottom, we enriched
the design in order to improve the estimation of the functions, which
are then optimised.

\paragraph{Limitations and perspectives}

In this thesis, we focused on a variational approach, which is based
on the optimisation of an objective function. Based on this function,
we. However, we do not control the values of the function, when
exceeding this threshold. A similar approach could be developed based
on the CVaR (Conditional Value at Risk), also called \emph{expected
  shortfall}, in order to take into account the expected loss when
this happens.

We also did not focus on the moments of the objective
function.  Horsetail
matching~\cite{cook_extending_2017,cook_horsetail_2018} allows for a
finer tuning of the properties of the distribution of the calibrated
model $J(\hat{\kk},\UU)$, by comparing it to a target
distribution. Following this idea, as the distribution of the
conditional minimum $J^*(\UU)$ can be seen as an ideal distribution
(\emph{i.e.} the distribution that one could get if the calibrated
parameter had always been chosen optimally for all realisations of the
uncertain variable), the minimisation of a measure of misfit between
the distribution of $J^*(\UU)$ and of $J(\hat{\kk},\UU)$ may be worth
exploring, and minimised.

A Bayesian method could be performed in order to estimate the
posterior distribution of the parameter $\kk$ given the
observations. This task could be performed using the gradient
information.


The new criteria introduced in this thesis rely on an additional
parameter, the maximal threshold or the wanted probability, that
controls the deviation with respect to the conditional optimal
value. Setting one of those parameters can lead to an unsatisfactory
counterpart as mentioned in~\cref{chap:robust_estimators}. In terms of
numerical methods, Gaussian Processes are not well suited for problems
of dimension larger than about \num{10}: when too large designs are
considered, fitting the GP can also be problematic, as large matrices
need to be inversed, and the optimisation of the hyperparameters is
difficult.  When looking to apply methods based on GP, a first
reduction of the input space may then be necessary.  The segmentation
we performed is rather coarse, and based on external information. A
finer dimension reduction method could be done, without prior
information, using the gradient for
instance~\cite{benameur_refinement_2002,zahm_certified_2018}.




\todo{Bayesian approach}
\todo{Using gradient informations for kriging}
\todo{Enrichment of the design with 2 stages for focused optimisation}
\todo{Better sampling scheme for margins of uncertainties}

\todo{Gradient info for dimension reduction}
%\todo{Wrapping up}
% \todo{Limitations}
% \todo{Perspectives}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vfill
\etoile
\vfill

\subfileLocal{
	\pagestyle{empty}
	\bibliographystyle{alpha}
        \bibliography{/home/victor/acadwriting/bibzotero}
}
% \relax

% \endgroup
\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Main_ManuscritThese"
%%% End:
