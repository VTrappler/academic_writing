\documentclass[../../Main_ManuscritThese.tex]{subfiles}

\subfileGlobal{
\renewcommand{\RootDir}[1]{./Text/Introduction/#1}
}

% \subfileLocal{
% \externaldocument{../../Text/Chapter2/build/Chapter2}
% \externaldocument{../../Text/Chapter3/build/Chapter3}
% \externaldocument{../../Text/Chapter4/build/Chapter4}
% \externaldocument{../../Text/Chapter5/build/Chapter5}
% \externaldocument{../../Text/Conclusion/build/Conclusion}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CHAPTER TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\pagestyle{introStyle}
\chapter*{Introduction}
\TitleBtwLines
\phantomsection
\addstarredchapter{Introduction}
\label{chap:Introduction}
% \subfileLocal{\pagestyle{contentStyle}}
% \todo{\cite{mcwilliams_irreducible_2007,zanna_ocean_2011}}
To understand and to be able to forecast natural phenomena is crucial
for many applications with high social, environmental and economic
stakes.  In earth sciences especially, the modelling of the ocean and
the atmosphere is important for day to day weather forecasts,
hurricanes tracking, or pollutant dispersion for instance. %, or biological monitoring.

Those natural phenomena are then modelled mathematically, usually by
representing the physical reality with some general equations
(Navier-Stokes equations in Computational Fluid Dynamics typically),
and by making successive reasonable assumptions, simplifications and
discretisations in order to be able to implement appropriate
solvers.%in
% order to account for the relative scales of the processes involved,
% and discretizations, 
%Indeed, some small scale processes, such as
% turbulences, are notoriously hard to model.
% and a fine knowledge of
% those may not be completely relevant for the foreseen application of
% the model.

Models are then only a partial representation of the reality, which
aim at representing complex processes that occur across a large range
of scales, scales that interact with each other. By essence, no
modelling system would be able to take all of those into account but
instead, their effect are incorporated in the modelling by overly
simplifying them and by {parametrizing} them.

In ocean modelling, and especially in coastal regions, a telling
example of this is the parametrization of the bottom friction. This
phenomenon occurs as the asperities of the ocean bed dissipates energy
through turbulences, and thus affects the circulation at the
surface. Since this happens at a subgrid level, \emph{i.e.} at a scale
usually several order of magnitudes below the scale of the domain
after discretization, modelling all those turbulences is completely
unfeasible in practice: the knowledge of the ocean bed is too limited
for such applications and the computational power required would be
unthinkable. Instead, the effect of the bottom friction is accounted
for through parametrization, so by introducing a new parameter which
is defined at every point of the mesh.
This parametrisation, or more precisely, the estimation of this
parameter will motivate the work carried in this thesis.

As this modelling is supposed to represent the reality, the prediction
should be compared with some data acquired through observations. This
comparison usually takes the form of the definition of a misfit
function $J$ that measures the error between the forecast and the
observations. This objective function is then minimised with respect to
some chosen parameters
$\kk$~\cite{das_estimation_1991,das_variational_1992,boutet_estimation_2015}
in order to get a calibrated model. Those parameters will be called
the \emph{control parameters}.

% Those calibrated models are often used to make decisions afterward,
% such as emergency evacuations plans, or optimisation of the position
% of turbines, or for forecasts. 
However, the parameters introduced are not the only source of errors
in the modelling.  % Garder ?
For such complex systems, some additional inputs are subject to
unrepresented statistical fluctuations~\cite{zanna_ocean_2011},
manifesting themselves at the boundary conditions, or in the forcing
of the model for instance. Such \emph{intrinsic} uncertainties are
often subject to variability, and neglecting this can lead to further
errors~\cite{mcwilliams_irreducible_2007}, or aberrant
predictions~\cite{kuczera_there_2010}.
We chose to model this
additional source of uncontrollable uncertainty with a random variable
$\UU$.  Because of this, the objective function is then a function which
takes two arguments: the parameter to calibrate $\kk$,
and some other parameter $\uu$, which can be thought as a realisation
of the random variable $\UU$, that we shall call \emph{environmental}
parameter.

Due to the presence of this random source of uncertainty, we wish to
calibrate the model, \emph{i.e.} to select a value of the control
parameter $\kk$, in a manner that guarantees that the model represents
accurately enough the reality, despite the random nature of the value of
the environmental parameter. In other words, as the objective function
measures in some sense the quality of the calibration, we wish that
this function exhibits \emph{acceptable} values as often as possible,
when $\kk$ is fixed. This defines intuitively the underlying notion of
\emph{robustness} with respect to the variability of the uncertain
variable.

In this thesis, we will study an aspect of the calibration of a
numerical model under uncertainty, by discussing the notions of
robustness, and by proposing a new family of criteria.  Specific
methods will also be introduced, and applied to the calibration of a
numerical model of the ocean. The thesis is organised as follows:
\begin{itemize}
\item in~\cref{chap:inverse_problem}, we introduce notions of
  statistics and probabilities that we will use to define the
  calibration problem. More specifically, the statistical and Bayesian
  inference problems will be broached, as well as some aspects of
  nested model selection using the likelihood ratio test. The link
  between probabilistic formulations of the inference problem, and
  variational approach based on the optimisation of a specified
  objective function will be emphasized.
  
\item in~\cref{chap:robust_estimators}, we are going to discuss some
  of the notions of robustness that can be found in the literature,
  either from a probabilistic inference aspect, or throught the prism
  of optimisation under uncertainties. Most existing methods rely on
  the optimisation of the moments of $\kk\mapsto J(\kk,\UU)$
  (in~\cite{lehman_designing_2004,janusevskis_simultaneous_2010}),
  while other methods are based on multiobjective problems, such as
  in~\cite{baudoui_optimisation_2012,ribaud_krigeage_2018}.% These
  % approaches may compensate some bad performances by some very good
  % ones, as we are averaging with respect to $\UU$.

  We propose a new family of criteria, which are based on the
  comparison between the objective function at a couple $(\kk,\uu)$
  and its optimal value given the same environmental variable. This
  notion of regret, either relative or additive, is then optimised in
  the sense of minimising the probability of exceeding a specified
  threshold, or to minimise one of its quantile, in order to control
  with high enough probability its variations. This work has led to
  the publication of an article~\cite{trappler_robust_2020}.
  
\item The family of criteria introduced in
  \cref{chap:robust_estimators} can be quite expensive to evaluate,
  that is why in~\cref{chap:adaptative_design_gp}, we will discuss the
  use of metamodels, Gaussian Processes especially, in order to choose
  iteratively the new points to evaluate. The process of selection,
  called \emph{SUR} method~\cite{bect_sequential_2012} (Stepwise
  Uncertainty Reduction) will depend on the type of robust estimation
  we wish to carry. Different methods will be proposed in order to
  estimate members of the regret-based family of robust
  estimators. These approaches differ by the measure of uncertainty on
  the function we wish to optimise. We will also introduce methods in
  order to select a batch of points, in order to take advantage of
  parallelism when available.

\item Finally, in~\cref{chap:croco}, we will study the calibration of
  a regional coastal model based on
  CROCO\footnote{\url{https://www.croco-ocean.org/}}. This study will
  focus on the estimation of the bottom friction parameter, where some
  uncertainties are introduced in the form of small perturbations of
  the amplitude of some tidal constituents, that force the model.
  This problem will be treated using twin experiments, where the
  observations will in fact be generated using the model.
  
  The definition of the problem will require first to segment the
  input space, and to quantify the influence of each input variable,
  using \emph{global sensitivity
    analysis}~\cite{iooss_revue_2011}. Based on this analysis, The
  input space will be reduced, in order to carry a tractable robust estimation, using some of the methods proposed in~\cref{chap:adaptative_design_gp}.
\end{itemize}
\markchapterend
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%           PREVIOUSLY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Numerical models are widely used to study or forecast natural
% phenomena and improve industrial processes.
% However, by essence models
% only partially represent reality and sources of uncertainties are
% ubiquitous (discretisation errors, missing physical processes, poorly
% known boundary conditions). Moreover, such uncertainties may be of
% different nature.~\cite{walker_defining_2003} proposes to consider two
% categories of uncertainties:
% \begin{itemize}
% \item Aleatoric uncertainties, coming from the inherent variability of
% a phenomenon, \emph{e.g.} intrinsic randomness of some environmental
% variables
% \item Epistemic uncertainties coming from a lack of knowledge about
% the properties and conditions of the phenomenon underlying the
% behaviour of the system under study
% \end{itemize} The latter can be accounted for through the introduction
% of ad-hoc correcting terms in the numerical model, that need to be
% properly estimated. Thus, reducing the epistemic uncertainty can be
% done through parameters estimation approaches. This is usually done
% using optimal control techniques, leading to an optimisation of a well
% chosen cost function which is typically built as a comparison with
% reference observations.
%   %
%   An application of such an approach, in the context of ocean
% circulation modeling, is the estimation of ocean bottom friction
% parameters in~\cite{das_estimation_1991}
% and~\cite{boutet_estimation_2015}.

 
  
%   The calibration often takes the form of the minimisation of a
% function $J$, that describes a distance between the output of the
% numerical model and some given observed data, plus generally some
% regularization terms.  In our study, this cost function takes two
% types of arguments: $\kk\in\Kspace$ that represents the parameters to
% calibrate, and $\uu\in\Uspace$, that represents the environmental
% conditions.  We assume that the environmental conditions are uncertain
% by nature, and thus will be modelled with a random variable $\UU$, to
% account for these aleatoric uncertainties.  This is then the random
% variable $J(\kk,\UU)$ that we want to minimise ``in some sense'' with
% respect to $\kk$.



  
%   We propose to compare the value of the objective function to the
% best value attainable given the environmemtal conditions at this
% point, with the idea that we want to be as close as possible, and as
% often as possible, to this optimal value. Introducing the relative
% regret, that is the ratio of the objective function by its conditional
% optimum, we can define a new family of robust estimators.

%   Within this family, choosing an estimator consists in favouring
% either its robustness, \emph{e.g} its ability to perform well under
% all circumstances, or on the contrary favour near-optimal
% performances, transcribing a risk-averse or a risk-seeking behaviour
% from the user.
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfileLocal{
	\pagestyle{empty}
	\bibliographystyle{alpha}
	\bibliography{../../bibzotero}
}
\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Main_ManuscritThese"
%%% End:
