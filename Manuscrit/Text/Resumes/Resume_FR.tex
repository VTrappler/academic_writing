\documentclass[../../Main_ManuscritThese.tex]{subfiles}

\subfileGlobal{
\renewcommand{\RootDir}[1]{./Text/Resumes/#1}
}

\newcommand{\frchap}[1]{\hyperref[#1]{Chapitre}~\ref{#1}}

% \subfileLocal{
% \externaldocument{../../Text/Chapter2/build/Chapter2}
% \externaldocument{../../Text/Chapter3/build/Chapter3}
% \externaldocument{../../Text/Chapter4/build/Chapter4}
% \externaldocument{../../Text/Chapter5/build/Chapter5}
% \externaldocument{../../Text/Conclusion/build/Conclusion}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CHAPTER TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\chapter*{Résumé Français}
\TitleBtwLines

\phantomsection
\addstarredchapter{Résumé Français}
\label{chap:resume_fr}
%\newpage
%\minitoc
\pagestyle{resumeStyle}

                                % \subfileLocal{\pagestyle{contentStyle}}
\subsection*{Présentation générale et calibration de modèles}
De nombreux phénomènes naturels sont modélisés afin de mieux connaître
leurs comportements et de pouvoir les prévoir.  Cependant, lors du
processus de modélisation, de nombreuses sources d'erreurs sont
introduites. Elles proviennent par exemple des paramétrisations qui
rendent compte des phénomènes sous-mailles, ou bien de l'ignorance des
conditions environnementales réelles dans lesquelles le phénomène est
observé.

De manière plus formelle, on peut distinguer deux types d'incertitudes
dans ces modèles, comme évoqué dans~\cite{walker_defining_2003}.
\begin{itemize}
\item les incertitudes dites \emph{épistémiques}, qui proviennent d'un
  manque de connaissance sur des charactéristiques du phénomène
  étudié, mais qui pourraient être réduites
\item les incertitudes dites \emph{aléatoires}, qui proviennent
  directement de la variabilité intrinsèque du phénomène étudié.
\end{itemize}

Dans le cadre de cette thèse, les incertitudes épistémiques prennent
la forme de la méconnaissance de la valeur d'un paramètre
$\kk \in \Kspace$, que l'on va chercher à calibrer.  Un exemple de ce
genre de problème est l'estimation de la friction dans les modèles
océaniques.  En effet, la friction de fond est dûe à la rugosité du
plancher océanique, provoquant de la dissipation d'énergie à cause des
turbulences engendrées. L'estimation de la friction de fond est un
problème à fort enjeu, notamment dans les régions côtières, du fait de
son influence sur les courants et de son interaction avec la
marée~\cite{sinha_principal_1997,boutet_estimation_2015}.

Cette estimation qui a déjà été traité dans un cadre
d'assimilation de données avec des méthodes variationelles comme
dans~\cite{das_estimation_1991,das_variational_1992} sur un cas
simplifié, ou dans un cas plus réaliste
dans~\cite{boutet_estimation_2015}, avec une méthode de gradient
stochastique, permettant de se passer du calcul du gradient.


Les incertitudes aléatoires, quant à elles, représentent des
conditions environnementales, comme le forçage d'un modèle ou les
conditions aux bords. Ces conditions ne sont pas directement
contrôlées par le modèle, donc l'on subit leurs fluctuations, ou leur
imprécision.

Ces variables environnementales vont être modélisées par une variable
aléatoire $\UU$, de réalisation $\uu\in \Uspace$.

Comme le modèle que l'on cherche à calibrer vise à représenter la
réalité, il est souhaitable que les predictions du modèle soient le
plus similaire possible aux observations dont on dispose. Cette notion
de distance est retranscrite en définissant une fonction $J$, dite
fonction coût ou fonction objectif qui mesure l'écart entre la sortie
du modèle et les observations disponible. Cette fonction prendra donc
en entrée le paramètre à estimer $\kk$, que l'on nommera paramètre de
contrôle, ainsi que $\uu$, le paramètre environnemental:

\begin{equation}
  \label{eq:def_J}
  \begin{array}{rccc}
   J: & \Kspace\times\mathbb{U}& \rightarrow& \mathbb{R}_+ \\
   &(\kk,\uu)& \mapsto& J(\kk,\uu)
  \end{array}
\end{equation}

La définition de la fonction coût dans un problème de calibration sera abordé dans le~\frchap{chap:inverse_problem}.

\subsection*{Notions de robustesse}

Ne pas prendre en compte les incertitudes aléatoires dans l'estimation
de $\kk$ peut amener à compenser de manière artificielle l'erreur
aléatoire, et donc amener à un comportement analogue au
\emph{sur-apprentissage} (overfitting), ou \emph{optimisation
  localisée}~\cite{huyse_probabilistic_2002}. Cela peut amener à des
situations où le paramètre estimé n'est optimal que pour la valeur de
$\uu$ supposée, et pour une autre réalisation de la variable aléatoire
sous-jacente, le modèle ainsi calibré donne des prédictions
potentiellement aberrantes~\cite{kuczera_there_2010}.

On cherche donc à définir une valeur de $\kk$, notée $\hat{\kk}$ de
manière à ce que $J(\hat{\kk}, \uu)$ reste \emph{acceptable}, lorsque
l'on prend en compte la variabilité intrinsèque de $\uu$.
En prenant en compte le caractère aléatoire de la variable
environnementale, pour un $\kk$ donné, la fonction coût peut être vue
comme une variable aléatoire: $J(\kk,\UU)$, que l'on va chercher
intuitivement à ``minimiser'' dans un certain sens qui reste à
définir.  Cette problématique porte différents noms, comme
l'optimisation robuste, où robuste doit être compris comme
l'insensibilité aux variations de $\UU$, optimisation sous
incertitudes (\emph{Optimisation under Uncertainty} ou \emph{OUU}), ou encore
d'optimisation stochastique. Une nomenclature prenant en compte les
différences notamment sur les contraintes potentiellement présentes
peut être trouvé dans~\cite{lelievre_consideration_2016}


L'objectif de la thèse est d'établir différents critères de
robustesse, et d'appliquer des méthodes adaptées permettant d'estimer
un paramètre en présence d'incertitudes. Cette estimation se réalise
dans un premier temps dans des cas simples (fonctions analytiques,
problèmes simplifiés de faibles dimensions), puis sur des problèmes
plus complexes d'estimation de la friction de fond (modèles réalistes
coûteux en temps de calcul, dimension élevée).

\subsection*{Critères basés sur le regret additif et relatif}
Dans le \frchap{chap:robust_estimators}, nous abordons le problème de
calibration 
Un certain nombre des méthodes
d'optimisation sous incertitudes se basent sur la minimisation des
moments de la variable aléatoire $J(\mathbf{\cdot}, \UU)$ comme
dans~\cite{lehman_designing_2004,janusevskis_simultaneous_2010}, ou
bien se basent sur la résolution d'un problème
multiobjectifs~\cite{baudoui_optimisation_2012,ribaud_krigeage_2018}.

Dans le cadre de cette thèse, nous proposons une approche basée sur le
regret, qui consiste à comparer les valeurs de la fonction $J$ avec le
\emph{minimum conditionnel}, qui est le minimum de la fonction
$J(\cdot, \uu)$, où $\uu$ est une réalisation de la variable aléatoire
$\UU$. Le minimum conditionnel est donc défini par
\begin{equation}
  \label{eq:Jstar}
  J^*(\uu) = \min_{\kk\in\Kspace} J(\kk,\uu)
\end{equation}
et le \emph{minimiseur conditionnel} associé est
\begin{equation}
  \label{eq:Kstar}
  \kk^*(\uu) = \argmin_{\kk\in \Kspace}J(\kk,\uu)
\end{equation}
Ceci permet de définir le regret additif: $J - J^*$. Étant donné la
strict positivité de $J$, nous pouvons définir aussi le regret relatif
$J/J^*$. Ceci nous permet d'introduire une notion
d'\emph{acceptabilité}, à entendre dans le sens d'écart par rapport au
minimum conditionnel.

Pour un $\uu\in\Uspace$ donné, $\kk\in\Kspace$ est dit
$\beta$-acceptable si $J(\kk, \uu) \leq J^*(\uu) + \beta$, pour
$\beta \geq 0$. La notion de $\beta$-acceptabilité est donc associée
au regret additif: $J(\kk, \uu) - J^*(\uu)$.  Similairement, on
définit la notion de $\alpha$-acceptabilité: $\kk$ est dit
$\alpha$-acceptable si $J(\kk, \uu) \leq \alpha J^*(\uu)$, pour
$\alpha > 1$ Dans la suite, sous nous intéresserons plus
particulièrement au regret relatif, qui permet de mieux prendre en
compte les variations de magnitude de la fonction objectif, mais les
définitions suivantes peuvent être adaptée au regret additif.


En prenant en compte le caractère aléatoire de $\UU$, nous pouvons
donc étudier la probabilité pour un point $\kk$, d'être acceptable:
\begin{equation*}
\Gamma_{\alpha}(\kk) = \Prob_{\UU}\left[J(\kk,\UU) \leq \alpha J^*(\UU) \right]
\end{equation*}
Cette probabilité peut donc être optimisée, pour donner
\begin{equation}
  \kk_{\mathrm{RR},\alpha} = \argmax_{\kk \in\Kspace} \Gamma_\alpha(\kk)
\end{equation}
L'optimum atteint est donc la probabilité maximale avec laquelle le
regret-relatif est borné par $\alpha$.


Si, au lieu de choisir un seuil $\alpha$ pour la minimisation, nous
cherchons plutôt à atteindre une certaine probabilité d'acceptabilité
$p$, nous pouvons définir la fonction quantile du regret relatif comme
\begin{equation}
  q_p(\kk) = Q_{\UU}\left(\frac{J(\kk,\UU)}{J^*(\UU)};p\right)
\end{equation}
où $Q_{\UU}(\cdot;p)$ est la fonction quantile à l'ordre $p$ de la
variable aléatoire en argument. $q_p(\kk)$ qui représente donc la valeur qui
borne le regret au point $\kk$ avec une probabilité donnée $p$.
Ce quantile peut aussi être minimisé, donnant
\begin{equation}
  \kk_{\mathrm{RR},\alpha_p} = \argmin_{\kk \in \Kspace} q_p(\kk)
\end{equation}
et le minimum atteint est par conséquent $\alpha_p$, qui vérifie
$\Gamma_{\alpha_p}(\kk_{\mathrm{RR},\alpha_p}) = p$.
  
D'après ces deux formulations nous pouvons donc soit: chercher à
maximiser la probabilité $\Gamma_{\alpha}$ pour $\alpha > 1$ bien
choisi, soit chercher à minimiser le quantile $q_p$, au niveau de
confiance $p$.

Ces critères dépendent donc d'un paramètre additionel, $\alpha$, ou
$p$ selon la formulation choisie, qui va permettre d'ajuster le
caractère \emph{conservatif} de la solution. En effet, choisir une
grande valeur de $\alpha$ (ou $p$ très proche de $1$) permet de se
prévenir des hautes déviations avec un grande probabilité. Si à
l'inverse, $\alpha$ est choisi plus faible, on favorisera les
solutions qui donnent des valeurs de la fonction objectif proches du
minmum atteignable, mais potentiellement avec une probabilité plus
faible.
  
Ce travail a mené à la publication de~\cite{trappler_robust_2020}.
  
\subsection*{Optimisation robuste et processus Gaussiens}
D'un point de vue pratique, ces notions de minimiseur conditionnel et
de minimum conditionnel peuvent s'avérer difficiles et chères à
calculer, car nécessitant une procédure d'optimisation. De plus, la
connaissance de la fonction objectif doit être suffisante afin de
calculer assez précisemment les quantités $\Gamma_{\alpha}$ et $q_p$.
Dans le \frchap{chap:adaptative_design_gp}, nous proposons d'utiliser
des processus Gaussiens (GP), afin de créer un modèle de substitution
permettant de se passer d'une connaissance exhaustive de la fonction
$J$.

Soit $Z$ le GP construit avec un plan d'expérience
$\mathcal{X}=\{(\kk_i, \uu_i), J(\kk_i, \uu_i)\}_{1\leq i \leq N}$. Le
métamodèle associé à $Z$ et construit d'après $\mathcal{X}$ sera noté
$m_Z:\Kspace\times \Uspace \rightarrow \mathbb{R}$.

Les propriétés des GP nous permettrons aussi d'établir des stratégies
d'enrichissement. En effet, des méthodes existantes dites
\emph{adaptatives} permettent d'améliorer l'estimation de diverses
quantités, comme la probabilité de défaillance
\cite{razaaly_rare_2019,moustapha_quantile-based_2016,bect_sequential_2012},
ou les minimiseurs et minimums conditionnels
dans~\cite{ginsbourger_bayesian_2014}. Ces méthodes, parfois appelées
méthodes SUR (\emph{Stepwise Uncertainty reduction}, réduction
d'incertitude séquentielle) sont basées sur la définition d'un
\emph{critère} $\kappa$, dont le maximiseur va être évalué par la fonction
originale:
\begin{equation}
  (\kk_{n+1}, \uu_{n+1}) = \argmax_{(\kk,\uu) \in \Kspace\times\Uspace} \kappa(\kk, \uu; Z)
\end{equation}
Puis le plan d'expérience est enrichi:
$\mathcal{X}_{n+1} = \mathcal{X}_n \cup \{(\kk_{n+1}, \uu_{n+1}),
J(\kk_{n+1}, \uu_{n+1})\}$, et $Z$ est mis à jour avec le nouveau plan
d'expérience $\mathcal{X}_{n+1}$.  Ce critère va donc représenter une
mesure de l'incertitude sur l'estimation, que l'on va chercher à
réduire. Nous allons ainsi proposer plusieurs méthodes permettant
d'améliorer l'estimation de $\Gamma_{\alpha}$ ou de $q_p$. Ceci sera fait en définissant notamment
\begin{equation}
  \Delta_{\alpha} = Z - Z^*
\end{equation}

Nous proposons aussi des méthodes basées sur l'échantillonage d'une
variable aléatoire, qui représente des points à forte incertitudes par
rapport à l'objectif final, comme
dans~\cite{echard_ak-mcs_2011,razaaly_rare_2019}. Après une procédure
de réduction statistique, comme le partitionnement (ou
\emph{clustering} en anglais), on peut donc évaluer et ajouter au plan
d'expérience un \emph{lot} de points, et ainsi prendre avantage du
parallélisme quand une telle architecture est disponible.


\subsection*{Application au code de calcul CROCO}
Dans le \frchap{chap:croco}, nous nous intéressons à la calibration
robuste d'un modèle réaliste d'océan, basé sur le code de
calcul.

Comme mentionné plus tôt, nous cherchons à estimer un paramètre
régissant la friction de fond. Cette étude sera effectuée dans un
cadre d'expériences jumelles, c'est-à-dire que les observations seront
obtenues grâce au code de calcul.

Nous effectuerons tout d'abord une optimisation de la fonction
objectif, sans introduire d'incertitudes. Ensuite, dans le but de
réduire la dimension du problème, nous segmenterons le domaine
océanique étudié, selon le type de sédiments qui se trouve au
fond. Afin de quantifier l'influence de chacune des régions délimitée
par la classe de sédiments, une analyse de sensibilité globale sera
effectuée, afin de calculer les indices de Sobol'
correspondants~\cite{sobol_global_2001,iooss_revue_2011}. Une étude
similaire sera menée pour les différentes composantes du paramètre
représentant les incertitudes $\uu$.

Enfin, une fois la dimension du problème de calibration réduite
significativement, nous appliquerons des méthodes présentées au
chapitre précédent.



\todo{fini ?}


\etoile
\vfill

% Pour le futur et la fin de la thèse, plusieurs points sont à considérer:
% \begin{itemize}
% \item Des méthodes permettant un contrôle plus fin sur les propriétés recherchées du paramètre (aversion/recherche du risque) sont à explorer, comme le ``horsetail matching''~\cite{cook_horsetail_2018}, en prenant notamment pour cible la distribution des minimums.
% \item L'application à l'estimation de la friction de fond dans le cadre du modèle CROCO est à envisager. CROCO\footnote{\url{https://www.croco-ocean.org/}} (Coastal and Regional Ocean COmmunity model) est un modèle régional d'océan, notamment conçu pour des applications de modélisation côtières. La région étudiée dans le cadre de la thèse est la façade atlantique de la France. 
%   \begin{itemize}
%     \item Premièrement les incertitudes du modèle sont à spécifier. Une première piste envisagée est introduire des incertitudes sur les composantes de marée à ajouter dans le forçage.
%   \item La friction de fond, que l'on cherche à estimer, est un paramètre variant dans l'espace, et donc peut potentiellement être défini en chaque point du maillage d'un modèle. Ceci force à prendre en compte la possibilité d'une grande dimension de $\Kspace$. On peut donc s'interroger sur la façon dont les méthodes et les critères décrits vont se mettre à l'échelle, et sur la possibilité d'appliquer des procédures de réduction de dimension.
%   \item En plus de la possible grande dimension du problème, les modèles réalistes sont souvent très coûteux en terme de temps de calcul. Il serait donc intéressant de pouvoir réduire au plus les évaluations du code, en adoptant par exemples des méthodes basées sur l'utilisation de méta-modèles. 
%   \end{itemize}
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfileLocal{
	\pagestyle{empty}
	\bibliographystyle{alpha}
	\bibliography{../../bibzotero}
}
\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Main_ManuscritThese"
%%% End:
