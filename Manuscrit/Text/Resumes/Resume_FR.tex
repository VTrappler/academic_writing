\documentclass[../../Main_ManuscritThese.tex]{subfiles}

\subfileGlobal{
\renewcommand{\RootDir}[1]{./Text/Resumes/#1}
}

\newcommand{\frchap}[1]{\hyperref[#1]{Chapitre}~\ref{#1}}

% \subfileLocal{
% \externaldocument{../../Text/Chapter2/build/Chapter2}
% \externaldocument{../../Text/Chapter3/build/Chapter3}
% \externaldocument{../../Text/Chapter4/build/Chapter4}
% \externaldocument{../../Text/Chapter5/build/Chapter5}
% \externaldocument{../../Text/Conclusion/build/Conclusion}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CHAPTER TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\chapter*{Résumé Français}
\TitleBtwLines

\phantomsection
\addstarredchapter{Résumé Français}
\label{chap:resume_fr}
%\newpage
%\minitoc
\pagestyle{resumeStyle}

                                % \subfileLocal{\pagestyle{contentStyle}}
\subsection*{Présentation générale et calibration de modèles}
De nombreux phénomènes naturels sont modélisés afin de mieux connaître
leurs comportements et de pouvoir les prévoir.  Cependant, lors du
processus de modélisation, de nombreuses sources d'erreurs sont
introduites. Elles proviennent par exemple des paramétrisations qui
rendent compte des phénomènes sous-mailles, ou bien de l'ignorance des
conditions environnementales réelles dans lesquelles le phénomène est
observé.

De manière plus formelle, on peut distinguer grossièrement deux types d'incertitudes
dans ces modèles, comme évoqué dans~\cite{walker_defining_2003}.
\begin{itemize}
\item les incertitudes dites \emph{épistémiques}, qui proviennent d'un
  manque de connaissance sur des caractéristiques du phénomène
  étudié, mais qui pourraient être réduites
\item les incertitudes dites \emph{aléatoires}, qui proviennent
  directement de la variabilité intrinsèque du phénomène étudié.
\end{itemize}

Dans le cadre de cette thèse, les incertitudes épistémiques prennent
la forme de la méconnaissance de la valeur d'un paramètre
$\kk \in \Kspace$, que l'on va chercher à calibrer.  Un exemple de ce
genre de problèmes est l'estimation de la friction dans les modèles
d'océans.  En effet, la friction de fond est dûe à la rugosité du
plancher océanique, provoquant de la dissipation d'énergie à cause des
turbulences engendrées. L'estimation de la friction de fond est un
problème à forts enjeux, notamment dans les régions côtières, du fait de
son influence sur les courants et de son interaction avec la
marée~\cite{sinha_principal_1997,boutet_estimation_2015}.

Cette estimation peut être traitée dans un cadre
d'assimilation de données avec des méthodes variationelles comme
dans~\cite{das_estimation_1991,das_variational_1992} sur un cas
simplifié, ou dans un cas plus réaliste
dans~\cite{boutet_estimation_2015}, avec une méthode de gradient
stochastique, permettant de se passer du calcul du gradient.


Les incertitudes aléatoires, quant à elles, représentent des
conditions environnementales, comme le forçage d'un modèle ou les
conditions aux bords. Ces conditions ne sont pas directement
contrôlées par le modèle, donc l'on subit leurs fluctuations, ou leur
imprécision.  Ces variables environnementales vont être modélisées à
l'aide d'une variable aléatoire $\UU$, de réalisation notée
$\uu\in \Uspace$.

Comme le modèle que l'on cherche à calibrer vise à représenter la
réalité, il est souhaitable que les prédictions du modèle soient le
plus similaire possible aux observations dont on dispose. Cette notion
de distance est retranscrite en définissant une fonction $J$, dite
fonction coût ou fonction objectif qui mesure l'écart entre la sortie
du modèle et les observations disponibles. Cette fonction prendra donc
en entrée le paramètre à estimer $\kk$, que l'on nommera paramètre de
contrôle, ainsi que $\uu$, le paramètre environnemental:

\begin{equation*}
  \label{eq:def_J}
  \begin{array}{rccc}
   J: & \Kspace\times\mathbb{U}& \rightarrow& \mathbb{R}_+ \\
   &(\kk,\uu)& \mapsto& J(\kk,\uu)
  \end{array}
\end{equation*}

La définition de la fonction coût dans un problème de calibration sera
abordé dans le~\frchap{chap:inverse_problem}.

\subsection*{Notions de robustesse}

Ne pas prendre en compte les incertitudes aléatoires dans l'estimation
de $\kk$ peut amener à compenser de manière artificielle certains
aspects physiques dûs à la variable environnementale, et donc amener à
un comportement analogue au \emph{sur-apprentissage} (overfitting), ou
\emph{optimisation localisée}~\cite{huyse_probabilistic_2002}: des
situations où le paramètre estimé n'est optimal que pour la valeur de
$\uu$ supposée, et pour une autre réalisation de la variable aléatoire
sous-jacente, le modèle ainsi calibré donne des prédictions
potentiellement aberrantes~\cite{kuczera_there_2010}.

On cherche donc à définir une valeur de $\kk$, notée $\hat{\kk}$ de
manière à ce que $J(\hat{\kk}, \uu)$ reste \emph{acceptable} lorsque
l'on prend en compte la variabilité intrinsèque de $\uu$. Comme $\UU$
est une variable aléatoire, pour un $\kk$ donné, la fonction coût peut
être elle aussi vue comme une variable aléatoire: $J(\kk,\UU)$, que
l'on va chercher intuitivement à ``minimiser'' dans un certain sens
qui reste à définir.  Cette problématique porte différents noms, comme
l'optimisation robuste, où cette robustesse doit être comprise comme
l'insensibilité aux variations de $\UU$, l'optimisation sous
incertitudes (\emph{Optimisation under Uncertainty} ou \emph{OUU}), ou
encore d'optimisation stochastique. Une nomenclature prenant en compte
les différences, notamment sur les contraintes potentiellement
présentes, peut être trouvé dans~\cite{lelievre_consideration_2016}


L'objectif de la thèse est donc de proposer différents critères de
robustesse, et d'appliquer des méthodes adaptées permettant d'estimer
un paramètre en présence d'incertitudes. Cette estimation se réalise
dans un premier temps dans des cas simples (fonctions analytiques,
problèmes simplifiés de faibles dimensions), puis sur des problèmes
plus complexes d'estimation de la friction de fond.

\subsection*{Critères basés sur le regret additif et relatif}
Dans le \frchap{chap:robust_estimators}, nous abordons le problème de
calibration en présence d'incertitudes. Un certain nombre des méthodes
d'optimisation sous incertitudes se basent sur la minimisation des
moments de la variable aléatoire $J(\mathbf{\cdot}, \UU)$ comme
dans~\cite{lehman_designing_2004,janusevskis_simultaneous_2010}, ou
les incorporent dans un problème d'optimisation
multiobjectifs~\cite{baudoui_optimisation_2012,ribaud_krigeage_2018}.

Dans le cadre de cette thèse, nous proposons une approche basée sur le
regret, qui consiste à comparer les valeurs de la fonction $J$ avec le
\emph{minimum conditionnel}, qui est le minimum de la fonction
$J(\cdot, \uu)$, où $\uu$ est une réalisation de la variable aléatoire
$\UU$. Le minimum conditionnel est donc défini par
\begin{equation*}
  \label{eq:Jstar}
  J^*(\uu) = \min_{\kk\in\Kspace} J(\kk,\uu)
\end{equation*}
et le \emph{minimiseur conditionnel} associé est
\begin{equation*}
  \label{eq:Kstar}
  \kk^*(\uu) = \argmin_{\kk\in \Kspace}J(\kk,\uu)
\end{equation*}

Ceci nous permet de définir différentes notions de regret: le regret
additif $J - J^*$ et étant donné la strict positivité de $J$, le
regret relatif $J/J^*$. Ceci nous permet d'introduire une notion
d'\emph{acceptabilité}, à entendre dans le sens d'écart par rapport au
minimum conditionnel.

Pour un $\uu\in\Uspace$ donné, $\kk\in\Kspace$ est dit
$\beta$-acceptable si $J(\kk, \uu) \leq J^*(\uu) + \beta$, pour
$\beta \geq 0$. La notion de $\beta$-acceptabilité est donc associée
au regret additif: $J(\kk, \uu) - J^*(\uu)$.  Similairement, on
définit la notion de $\alpha$-acceptabilité: $\kk$ est dit
$\alpha$-acceptable si $J(\kk, \uu) \leq \alpha J^*(\uu)$, pour
$\alpha > 1$. Dans la suite, sous nous intéresserons plus
particulièrement au regret relatif, qui permet de mieux prendre en
compte les variations de magnitude de la fonction objectif, mais les
définitions suivantes peuvent être adaptée au regret additif.


En prenant en compte le caractère aléatoire de $\UU$, nous pouvons
donc étudier la probabilité pour un point $\kk$, d'être $\alpha$-acceptable:
\begin{equation*}
\Gamma_{\alpha}(\kk) = \Prob_{\UU}\left[J(\kk,\UU) \leq \alpha J^*(\UU) \right]
\end{equation*}
Cette probabilité peut donc être optimisée, pour donner
\begin{equation*}
  \kk_{\mathrm{RR},\alpha} = \argmax_{\kk \in\Kspace} \Gamma_\alpha(\kk)
\end{equation*}
L'optimum atteint est donc la probabilité maximale avec laquelle le
regret-relatif est borné par $\alpha$.


Si, au lieu de choisir un seuil $\alpha$ pour la minimisation, nous
cherchons plutôt à atteindre une certaine probabilité d'acceptabilité
$p$, nous pouvons définir la fonction quantile du regret relatif comme
\begin{equation*}
  q_p(\kk) = Q_{\UU}\left(\frac{J(\kk,\UU)}{J^*(\UU)};p\right)
\end{equation*}
où $Q_{\UU}(\cdot;p)$ est la fonction quantile à l'ordre $p$ de la
variable aléatoire en argument. $q_p(\kk)$ représente donc la valeur qui
borne le regret au point $\kk$ avec une probabilité donnée $p$.
Ce quantile peut aussi être minimisé, donnant
\begin{equation*}
  \kk_{\mathrm{RR},\alpha_p} = \argmin_{\kk \in \Kspace} q_p(\kk)
\end{equation*}
et le minimum atteint est par conséquent $\alpha_p$, qui vérifie
$\Gamma_{\alpha_p}(\kk_{\mathrm{RR},\alpha_p}) = p$.
  
D'après ces deux formulations nous pouvons donc soit: chercher à
maximiser la probabilité $\Gamma_{\alpha}$ pour $\alpha > 1$ bien
choisi, soit chercher à minimiser le quantile $q_p$, au niveau de
confiance $p$.

Ces critères dépendent donc d'un paramètre additionel, $\alpha$, ou
$p$ selon la formulation choisie, qui va permettre d'ajuster le
caractère \emph{conservatif} de la solution. En effet, choisir une
grande valeur de $\alpha$ (ou $p$ très proche de $1$) permet de se
prévenir des hautes déviations avec un grande probabilité. Si à
l'inverse, $\alpha$ est choisi plus faible, on favorisera les
solutions qui donnent des valeurs de la fonction objectif proches du
minimum atteignable, mais potentiellement avec une probabilité plus
faible.  
Ce travail a mené à la publication de~\cite{trappler_robust_2020}.
  
\subsection*{Optimisation robuste et processus Gaussiens}
D'un point de vue pratique, ces notions de minimiseur conditionnel et
de minimum conditionnel peuvent s'avérer difficiles et coûteuses à
calculer, car nécessitant une procédure d'optimisation. De plus, la
connaissance de la fonction objectif doit être suffisante afin de
calculer assez précisemment les quantités $\Gamma_{\alpha}$ et $q_p$.
Dans le \frchap{chap:adaptative_design_gp}, nous proposons d'utiliser
des processus Gaussiens (GP), afin de créer un modèle de substitution,
bien moins coûteux à évaluer, permettant de se passer d'une
connaissance exhaustive de la fonction $J$.

Soit $Z$ le GP construit avec un plan d'expérience
$\mathcal{X}=\{(\kk_i, \uu_i), J(\kk_i, \uu_i)\}_{1\leq i \leq n}$,
comprenant donc $n$ points.  Le métamodèle associé à $Z$ et construit
d'après $\mathcal{X}$ sera noté
$m_Z:\Kspace\times \Uspace \rightarrow \mathbb{R}$, et utilisé en lieu
et en place de $J$ pour estimer $\Gamma_{\alpha}$ ou $q_p$, dans un
approche dite \emph{plug-in}.

Les propriétés des GP nous permettrons aussi d'établir des stratégies
d'enrichissement. En effet, des méthodes existantes dites
\emph{adaptatives} permettent d'améliorer l'estimation de diverses
quantités, comme la probabilité de défaillance
\cite{razaaly_rare_2019,moustapha_quantile-based_2016,bect_sequential_2012},
ou les minimiseurs et minimums conditionnels
dans~\cite{ginsbourger_bayesian_2014}. Ces méthodes, parfois appelées
méthodes SUR (\emph{Stepwise Uncertainty Reduction}, réduction
d'incertitude séquentielle) sont basées sur la définition d'un
\emph{critère} $\kappa$, dont le maximiseur va ensuite être évalué par la fonction
originale: 
\begin{equation*}
  (\kk_{n+1}, \uu_{n+1}) = \argmax_{(\kk,\uu) \in \Kspace\times\Uspace} \kappa\left((\kk, \uu); Z\right)
\end{equation*}
puis le plan d'expérience est enrichi avec ce nouveau point et son évaluation:
\begin{equation}
\mathcal{X}_{n+1} = \mathcal{X}_n \cup \{(\kk_{n+1}, \uu_{n+1}), J(\kk_{n+1}, \uu_{n+1})\}
\end{equation}
et enfin, $Z$ est mis à jour avec le nouveau plan d'expérience
$\mathcal{X}_{n+1}$.  Ce critère va donc représenter une mesure de
l'incertitude sur l'estimation, que l'on va chercher à réduire. Nous
allons ainsi proposer plusieurs méthodes permettant d'améliorer
l'estimation de $\Gamma_{\alpha}$ ou de $q_p$.  Nous proposons aussi
des méthodes basées sur l'échantillonage d'une variable aléatoire à
support dans $\Kspace\times \Uspace$, dont les échantillons sont des
points à forte incertitudes par rapport à l'objectif final, comme
dans~\cite{echard_ak-mcs_2011,razaaly_rare_2019}. Après une procédure
de réduction statistique, comme le partitionnement (ou
\emph{clustering} en anglais), on peut donc évaluer et ajouter au plan
d'expérience un \emph{lot} de points, et ainsi tirer parti du
parallélisme quand une telle architecture est disponible.

Ceci sera fait en définissant notamment
$Z^*(\uu) = Z(\kk^*(\uu),\uu)$, et
\begin{equation*}
  \Delta_{\alpha,\beta}(\kk, \uu) = Z(\kk, \uu) - \alpha Z^*(\uu) - \beta
\end{equation*}
et
\begin{equation*}
  \Xi(\kk, \uu) = \log\left(\frac{Z(\kk, \uu)}{Z^*(\uu)}\right)
\end{equation*}
qui sont deux processus stochastiques dont les distributions, exactes
sinon approchées, pourront être déduites à partir de la loi de $Z$.
Nous pourrons donc établir des stratégies d'enrichissement de plans
d'expériences par rapport à ces deux processus.


\subsection*{Application au code de calcul CROCO}
Dans le \frchap{chap:croco}, nous nous intéressons à la calibration
robuste d'un modèle réaliste d'océan, basé sur le code de calcul
CROCO.\@ Les incertitudes introduites dans ce cadre portent sur
l'amplitude de différentes composantes de marée.

Comme mentionné plus tôt, nous cherchons à estimer un paramètre
régissant la friction de fond. Cette étude sera effectuée dans un
cadre d'expériences jumelles, c'est-à-dire que les observations seront
obtenues grâce au code de calcul.

Nous effectuerons tout d'abord une optimisation de la fonction
objectif, sans introduire d'incertitudes. Ensuite, dans le but de
réduire la dimension du problème, nous segmenterons le domaine
océanique étudié selon le type de sédiments qui se trouve au
fond. Afin de quantifier l'influence de chacune des régions délimitée
par la classe de sédiments, une analyse de sensibilité globale sera
effectuée, afin de calculer les indices de Sobol'
correspondants~\cite{sobol_global_2001,iooss_revue_2011}. Une étude
similaire sera menée pour les différentes composantes du paramètre
représentant les incertitudes $\uu$.
Enfin, une fois la dimension du problème de calibration réduite
significativement, nous appliquerons des méthodes présentées au
chapitre précédent, afin d'estimer de manière robuste le paramètre de
friction de fond dans ce problème académique.

\markchapterend


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subfileLocal{
	\pagestyle{empty}
	\bibliographystyle{alpha}
	\bibliography{../../bibzotero}
}
\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Main_ManuscritThese"
%%% End:
