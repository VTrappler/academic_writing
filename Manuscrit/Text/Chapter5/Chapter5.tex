\documentclass[../../Main_ManuscritThese.tex]{subfiles}

\subfileGlobal{
\renewcommand{\RootDir}[1]{./Text/Chapter5/#1}
}
\newcommand{\CROCO}{CROCO}
\newcommand{\zob}{z_b}


\subfileLocal{
\externaldocument{../../Text/Introduction/build/Introduction}
\externaldocument{../../Text/Chapter2/build/Chapter2}
\externaldocument{../../Text/Chapter3/build/Chapter3}
\externaldocument{../../Text/Chapter4/build/Chapter4}
\externaldocument{../../Text/Conclusion/build/Conclusion}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CHAPTER TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\imgpath{/home/victor/acadwriting/Manuscrit/Text/Chapter5/img/} 


\begin{document}
% \subfileLocal{\dominitoc}
% \subfileLocal{\setcounter{chapter}{4}}
% \subfileLocal{\chapter{Application to the numerical coastal model CROCO}}
\chapter{Application to the numerical coastal model \CROCO}
\label{chap:croco}
\minitoc
% \newpage
\subfileLocal{\pagestyle{contentStyle}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Introduction}
\label{sec:intro_croco}

% \todo{\cite{mcwilliams_irreducible_2007,zanna_ocean_2011}}

In this chapter, we will study the problem of the calibration under
uncertainties of the friction parameter of the ocean bed of a realistic
numerical model of the Atlantic french coast, which is run using \CROCO. 

Since the bottom friction depends directly on the size of the
asperities on the ocean bed, it is a subgrid phenomenon, meaning that
the program does not solve the equations of motions of the fluid
around those asperities. Instead, the dissipation coming from this
rugosity is parametrized at every point of the mesh.

The bottom friction has been identified as a crucial parameter that,
if ill-specified, limits the accuracy of the
predictions~\cite{sinha_principal_1997,kreitmair_effect_2019},
especially in shallow water regions; consequently, there has been an
effort to control this parameter in various
studies~\cite{das_variational_1992,das_estimation_1991,boutet_estimation_2015}.
We will detail how bottom friction affects the oceanic circulation
in~\cref{ssec:modelling_bottom}, in order to get a first insight on
the regions that may influence the most the calibration.

The deterministic problem of calibration will then be addressed in
\cref{sec:deterministic_calibration_bott}, by first defining the cost
function and the input space. We will then calibrate the model without
external uncertainties using adjoint-based method, in high-dimension
($\sim$\num{15000}).

However for such problems, as the parameter may be spatially
distributed and thus high-dimensional, any procedure may become
quickly expensive.  In consequence, instead of considering each grid
point individually, we will segment the geographical input space in
different independent regions, which are based on the type of
sediments listed at the bottom of the water. In this problem of
calibration we will assume that the uncertainties take the form of an
environmental parameter which perturbates the amplitude of some tidal
constituents.  In order to quantify the influence of each of the
sediments-based regions, and each of the components of the
environmental variable, we will carry global sensitivity analysis,
in~\cref{sec:sensitivity-analysis}.

Finally, after this study that we will use to reduce significantly the
input space, we are going to apply some of the methods proposed in the
previous chapter, in order to get a robust estimation of the bottom
friction using Gaussian processes.



\section{\CROCO\ and bottom friction modelling}
\label{sec:croco_bottom_fr}
\CROCO{}\footnote{\CROCO\ and CROCO\_TOOLS are provided by
  \url{https://www.croco-ocean.org}} (Coastal and Regional Ocean
COmmunity model) is a program written in Fortran that describes the
motion of the ocean by solving the \emph{primitive equations}, which
are simplified versions of the Navier-Stokes equations, in order to
take into account the particular scales at play at the surface of the
Earth. \CROCO{} has been developed upon ROMS\_AGRIF, and is designed
to be coupled with other modelling systems, such as atmospheric,
biological or ecosystem models.

% gradually including algorithms from MARS3D (sediments) and
% HYCOM (vertical coordinates). An important objective for \CROCO\ is to
% resolve very fine scales (especially in the coastal area), and their
% interactions with larger scales. It is the oceanic component of a
% complex coupled system including various components, e.g., atmosphere,
% surface waves, marine sediments, biogeochemistry and ecosystems.


\subsection{Parameters and configuration of the model}
\label{sec:geographical_setting}

The configuration used in this thesis is based on the one used
in~\cite{boutet_estimation_2015}. The spatial domain ranges from
\ang{9}W to \ang{1}E and from \ang{43}N to \ang{51}N, and spans most
of the Bay of Biscay, the English Channel and the eastern part of the
Celtic Sea.  The resolution is \SI{1/14}{\degree}, which leads to a
mesh size between \SI{5}{\kilo\metre} and \SI{6}{\kilo\metre}. The
bathymetry map and the spatial domain is
shown~\cref{fig:depth_maps}. The ocean can be split roughly in two
regions, based on its depth : the region near the coasts which
correspond to the continental shelf, where the water depth is less
than \SI{200}{\meter}, and the offshore region of the Bay of Biscay,
where the depth is closer to \SI{5000}{\meter}.
\begin{figure}[ht]
  \centering
  \includegraphics{\imgpath depth_maps_log.png}
  \caption[Bathymetry chart of the domain modelled]{\label{fig:depth_maps} Bathymetry used in \CROCO, and
    geographical landmarks. The continental shelf correspond roughly
    to the area with depth less than \SI{200}{\meter} (green hue),
    while the abyssal plain has a depth larger than \SI{4000}{\meter}
    (blue hue)}
\end{figure}


\CROCO{} can solve the fluid motion equations in 3D, but in this
configuration, solves the shallow water equations instead, which are
obtained by vertically integrating the primitive equations.
% \begin{align}
    %     \left\{
    %     \begin{array}{rcl}
    %     \frac{\partial u}{\partial t} + \nabla \cdot \left(\vec{v}u\right) - fv &=& -\frac{\partial \phi}{\partial x} + \mathcal{F}_{u} + \mathcal{D}_u \\
    %     \frac{\partial v}{\partial t} + \nabla \cdot \left(\vec{v}v\right) + fv &=& -\frac{\partial \phi}{\partial y} + \mathcal{F}_{v} + \mathcal{D}_v
                                                                                      %   \end{array}
                                                                                      %                                                                                       \right.
                                                                                      %   \end{align}
\begin{align}
  \left\{
  \begin{array}{lll}
    \pfrac{\mathbf{v}}{t} + (\mathbf{v} \cdot \nabla )\mathbf{v} + 2 \bm{\Omega} \wedge \mathbf{v} & = & -g\nabla H + \frac{\bm{\tau}_b}{\rho H} + F \\
    \pfrac{H}{t} + \nabla (H \cdot \mathbf{v})                                                     & = & 0
  \end{array}
                                                   \right.
\end{align}
where $\mathbf{v} = (v_x,v_y)$ is the velocity field of the fluid,
$\bm{\Omega}$ is the rotational angular vector of Earth, $H$ is the
water column height, $g$ is the gravitational constant, $\rho$ is the
fluid density, and $\bm{\tau}_b$ is the shear stress at the
bottom. Finally, $F$ represents the forcing of the model, in this case
the influence of the tides.  The bottom friction affects the
circulation through $\bm{\tau}_b$, and different parameterizations of
this stress can be derived.

\subsection{Modelling of the bottom friction}
\label{ssec:modelling_bottom}
In \CROCO, the bottom friction is modelled using a quadratic drag
coefficient $C_d$:
\begin{equation}
  \label{eq:bottom_stress_tau}
  \bm{\tau}_b= -C_d \|\mathbf{v}_b\|\mathbf{v}_b 
\end{equation}
where $\mathbf{v}_b$ is the velocity at the bottom, so in the case
of the Shallow Water equations, $\mathbf{v}_b = \mathbf{v}$.  The
drag coefficient can also be formulated as a function of the water
column height and the \emph{bottom roughness} $\zob$ by assuming a
logarithmic profile of the velocity at bottom (a derivation can be found in~\cite{le_bars_amandes_2010} for instance)
\begin{equation}
  \label{eq:quadratic_friction_vonkarman}
  C_d = \left(\frac{\kappa}{\log\left(\frac{H}{\zob}\right) - 1}\right)^2% \text{for } C_d \in [C_d^{\min}, C_d^{\max}]
\end{equation}
where $\kappa$ is the Von K\'arm\'an constant, usually taken equal to
$0.41$.  The bottom roughness $\zob$, or \emph{rugosity} in this
document, can be interpreted as the size of the turbulent layer at the
bottom, induced by the asperities of the sediments.
\cite{boutet_estimation_2015} shows that in a calibration context,
controlling the rugosity $\zob$ yields better result than controlling
the drag coefficient $C_d$ due the influence of the water column
height $H$.
On~\cref{fig:cd_zob} is shown the drag coefficient $C_d$ as a function
of the roughness $\zob$ of the ocean floor, for different heights of
the water column $H$.
\begin{figure}[ht]
  \centering \input{\imgpath cd_zob.pgf}
  \caption[Drag coefficient $C_d$ as a function of the height and the roughness]{\label{fig:cd_zob} Drag coefficient $C_d$ as a function of
    the column water height and the roughness at the bottom}
\end{figure}


We can see that the higher the water column height, the less variation
appears when adjusting the bottom roughness $\zob$.  Considering the
physical properties of the bottom friction and the types of sediments,
it can be expected that the English Channel, and at a lesser extent
the rest of the continental shelf are the areas which are the most
influential for the calibration.


We are going to make the assumption that the size of the turbulent
layer at the bottom can be set equal to the typical size of the
sediments, so the rugosity is directly linked to the type of sediment
found on the ocean bed. \Cref{tab:size_sediments} presents a coarse
classification, along with the typical size of the sediments that can
be found, that will serve as a reference value, or \emph{truth value}
$\zob^{\mathrm{truth}}$.  % We can see that the rugosity spans several
% order of magnitude, hence it may be worth considering controlling the
% logarithm of the rugosity instead of the rugosity itself.

\begin{table}[!ht]
  \centering
  \begin{tabular}{rrrl} \toprule Code & Description & Size of the
    majority of particles             & $\zob^{\mathrm{truth}}$                                                                                  \\ \midrule
    R                                 & Rock        & Larger                                                         & \SI{50}{\milli\meter}     \\
    C                                 & Pebble      & $>$\SI{20}{\milli\metre}                                       & \SI{25}{\milli\meter}     \\
    G                                 & Gravel      & $\interval{\SI{20}{\milli\metre}}{\SI{2}{\milli\metre}}$       & \SI{7}{\milli\meter}      \\
    S                                 & Sand        & $ \interval{\SI{2}{\milli\metre}}{\SI{0.5}{\milli\metre}}$     & \SI{1}{\milli\meter}      \\
    SF                                & Fine Sand   & $ \interval{\SI{0.5}{\milli\metre}}{\SI{0.05}{\milli\metre}}$  & \SI{1.5e-1}{\milli\meter} \\
    Si                                & Silt        & $ \interval{\SI{0.05}{\milli\metre}}{\SI{0.01}{\milli\metre}}$ & \SI{2e-2}{\milli\meter}   \\
    V                                 & Muds        & $< \SI{0.05}{\milli\metre}$                                    & \SI{2e-2}{\milli\meter}
                                                                                                                                                 \\ \bottomrule
            %             A           & Clay        & $< \SI{0.01}{\milli\metre}$                                    & \bottomrule
  \end{tabular}
  \caption{\label{tab:size_sediments} Type of sediments and size of the majority of particles for each type of sediment}
\end{table}

Based on the documentation of the SHOM\footnote{Service hydrographique
  et océanographique de la Marine}, the \cref{fig:sediments_reduced}
shows a simplified version of the map of the repartition of the
different types of sediments. A more complete chart can be
found~\cref{fig:sediments_full}.
\begin{figure}[ht]
  \centering
  \includegraphics{\imgpath sediments_reduced.png}
  \caption{\label{fig:sediments_reduced} Repartition of the sediments
    on the ocean floor.}
\end{figure}

Most of the ocean floor in this region is composed of sand. Even
though siltic soil is listed, it is only scarcely present. The figure
also shows that the largest sediments are rocks but are mostly located
in the Bay of Biscay, near the boundary of the continental
shelf. Pebbles however are mostly located in the shallow region in the
English Channel, thus it may be expected that controlling the
roughness in the regions listed as pebbles will affects significantly
water circulation, and thus the sea surface height. Incidentally, we
can notice the inverse correlation between the size of the sediments,
and the depth at which they are found.

According to~\cref{tab:size_sediments}, the rugosity $\zob$ spans
multiple orders of magnitude, so we are then going to define the control
variable $\kk$ as
\begin{equation}
  \kk = \log \zob \in \Kspace = \interval{\kk_{\min}}{\kk_{\max}}^p
\end{equation}
where $\kk_{\min} = \log(10^{-5}) \approx -11.5$, and
$\kk_{\max} = \log(5\cdot 10^{-2}) \approx -3$.  The dimension of
$\Kspace$ will be written $p$, and will be specified depending on the
chosen segmentation.

\subsection{Tidal modelling and uncertainties}
\label{ssec:tidal_modelling}
The ocean, especially near the English Channel is driven by tidal
forces that produce current at the surface. As a periodic signal, the
tidal forcing is analysed harmonically, in order to separate its
influence by frequency. In \CROCO, this forcing comes from the TPXO
model of tides~\cite{egbert_efficient_2002}, and the configuration uses the 5
primary harmonic constituents as described \cref{tab:tides_components}.
\begin{table}[!h]
  \centering
  % % Chose order from the rank in the TPXO file :
                                                                                                               %                                                                                                                "M2 S2 N2 K2 K1 O1 P1 Q1 Mf Mm"
                                                                                                               %                                                                                                                " 1  2  3  4  5  6  7  8  9 10"
  \begin{tabular}{rrr}\toprule
    Darwin Symbol & Period (h)   & Species                           \\ \midrule
    $M_2$         & 12.4206      & Principal Lunar Semidiurnal       \\
    $S_2$         & 12           & Principal Solar Semidiurnal       \\
    $N_2$         & 12.65834751  & Larger Lunar Elliptic Semidiurnal \\
    $K_2$         & 11.96723606  & Lunisolar Semidiurnal             \\
    $K_1$         & 23.93447213  & Lunar Diurnal                     \\
            %             \midrule
            %             $O_1$         & 25.81933871  & Lunar Diurnal                     \\ 
            %             $P_1$         & 24.06588766  & Solar Diurnal                     \\
            %             $Q_1$         & 26.868350    & Larger Lunar Elliptic Diurnal     \\
            %             $M_f$         & 13.660830779 & Lunisolar Fortnightly             \\
            %             $M_m$         & 27.554631896 & Lunar Monthly                     \\
    \bottomrule
  \end{tabular}
  \caption{Harmonic constituents used in the configuration}
  \label{tab:tides_components}
\end{table}

By perturbating some properties of those tide components, we can
introduce a new variable that will act as \emph{uncertain variables} in
our numerical model.

In this work, we chose to add a small multiplicative error on the
amplitude on the different components of the tide.  Let
$\uu = (\uu_1,\dots,\uu_5)\in \Uspace = \interval{0}{1}^5$. Let $A_k$
be the amplitude of the $k$th component of the tide. The perturbated
amplitude $\tilde{A}_k$ is defined as
\begin{equation}
  \label{eq:tide_error}
  \tilde{A}_k(\uu_k) = A_k (1 + 0.01(2\uu_k - 1))
\end{equation}
where $\uu_k$ is the $k$th component of the uncertain variable $\uu$.
Based on this definition $\tilde{A}_k(0) = 0.99A_k$,
$\tilde{A}_k(0.5) = A_k$ and $\tilde{A}_k(1) = 1.01A_k$. This choice
has been made in order to represent some possible uncertainties on the
external forcing of the model. We also define $\uu^{\mathrm{truth}}$
as the vector whose all its components are set to \num{0.5}, so when
no amplitude is perturbated.

\section{Deterministic calibration of the bottom friction}
\label{sec:deterministic_calibration_bott}
The calibration of the bottom friction will be first studied without
external uncertainties, which corresponds to an unperturbated tidal
forcing. In terms of the environmental variable, it is equivalent to
$\uu^{\mathrm{truth}}$.
    %     $N_{\mathrm{obs}} = N_{\mathrm{mesh}}\cdot N_{\mathrm{time}}$

We are going to use the notations introduced
in~\cref{chap:inverse_problem} for the model. Let us define
$(\mathcal{M}(\cdot,\uu^{\mathrm{truth}}),\Kspace)$, the numerical
model we want to calibrate. The forward operator $\mathcal{M}$ is
defined by
\begin{equation}
  \begin{array}{rcl}
    \mathcal{M}: \Kspace  &\longrightarrow& \mathbb{R}^{N_{\mathrm{obs}}} \\
    \kk & \longmapsto & \mathcal{M}(\kk, \uu^{\mathrm{truth}}) = \left(\eta_{t,i}(\kk, \uu^{\mathrm{truth}})\right)_{\substack{1 \leq i \leq N_{\mathrm{mesh}} \\ 1 \leq t \leq N_{\mathrm{time}}}} \\ 
  \end{array}
\end{equation}
where $\eta_{t,i}(\kk,\uu)$ is the free surface height of the ocean at
the mesh point $i$, and at the time-step $t$, obtained using the model
and the bottom friction associated with $\kk$ and a perturbation on
the tide components of $\uu$.

\subsection{Twin experiment setup}
In a twin experiment setup, the observation $y$ are generated using
the numerical model, and a predefined truth value
$\kk^{\mathrm{truth}}$.  This means that the ``physical model'' is
defined using the forward operator $\mathscr{M}$, based on the forward
numerical model, evaluated with a certain uncertain parameter
$\uu^{\mathrm{truth}}$.
\begin{equation}
  \label{eq:twin_exp}
  \begin{array}{rcl}
    \mathscr{M}: \Kspace &\longrightarrow & \mathbb{R}^{N_{\mathrm{obs}}} \\
    \kk & \longmapsto &\mathscr{M}(\kk) = \mathcal{M}(\kk, \uu^{\mathrm{truth}})
  \end{array}
\end{equation}

Based on the forward operator $\mathscr{M}$, we can generate the
observations $y\in \Yspace = \mathbb{R}^{N_{\mathrm{obs}}}$ using the
truth value $\kk^{\mathrm{truth}}=\log \zob^{\mathrm{truth}}$, as
defined \cref{tab:size_sediments}:
\begin{equation}
  y = \mathscr{M}(\kk^{\mathrm{truth}}) = \mathcal{M}(\kk^{\mathrm{truth}}, \uu^{\mathrm{truth}})
\end{equation}

In the following, if the $\uu$ argument is omitted, it means that the
model, or subsequent functions are evaluated with
$\uu^{\mathrm{truth}}$.
\subsection{Cost function definition}
Once the observation $y \in \mathbb{R}^{N_{\mathrm{obs}}}$ have been generated, we can
define a cost function $J$ by
\begin{align}
  \label{eq:cost_fun_definition}
  J(\kk) &= \sum_{t=1}^{ N_{\mathrm{time}}}\sum_{i=1}^{N_{\mathrm{mesh}}}  \left(\eta_{t,i}(\kk,\uu^{\mathrm{truth}}) - y_{t, i}\right)^2 \\
         &= \|\mathcal{M}(\kk,\uu^{\mathrm{truth}}) - y\|_2^2
\end{align}
Equivalently, as mentioned in~\cref{chap:inverse_problem}, by assuming
that the distribution of the (random) observation vector is known and
$Y \mid \kk \sim \mathcal{N}(\mathcal{M}(\kk), I)$ (with $I$ being the
identity matrix of dimension $p$), $J$ is proportional to the negative
log-likelihood of the data.

\subsection{Gradient-descent optimisation}
\label{ssec:optim_gradient}
The optimisation is carried using M1QN3, a version of a
gradient-descent procedure, as described
in~\cite{gilbert_numerical_1989}. We can first look to control $\zob$
at every cell of the mesh: $\kk = (\kk_1,\cdots, \kk_p)$ where
$\kk_i = \log\zob^i$ and $p=\num{15684}$.

Due to the large number of points whose friction can be controlled, a
finite difference method to get the gradient is unfeasible. Instead,
Tapenade~\citep{hascoet_tapenade_2013}, an Automatic Differentiation
tool has been used in order to get the gradient (with respect to
$\kk$) of the cost function $J$ using the adjoint method, as
described~\cref{sec:calibration_adjoint_optimization}. The
optimisation procedure is stopped after \num{400} iterations, and the
estimated controlled parameter is
shown~\cref{fig:optimization_map_399}.  \Cref{fig:ctrl_true} shows the
evolution of the cost function and the squared norm of the gradient
during the optimisation procedure. %  \todo{plutot deviation
%   \cref{fig:optimization_map_399} ou log deviation ?
%   \cref{fig:optimization_map_399_log}}
% \begin{figure}[ht]
%   \centering
%   \includegraphics{/home/victor/optimisation_dahu/optim_sediments/map_399.png% /home/victor/optimisation_dahu/optim_true/map_150.png
%   }
%   \caption{\label{fig:optimization_map_399} Optimization of $\zob$ on
%     the whole space using gradient obtained via adjoint method, after
%     $400$ iterations.}
% \end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{/home/victor/optimisation_dahu/optim_sediments/map_log_400.png% /home/victor/optimisation_dahu/optim_true/map_150.png
  }
  \caption[Optimization of $\zob$ on the whole space]{\label{fig:optimization_map_399} Optimization of $\zob$ on
    the whole space using gradient obtained via adjoint method, after
    $400$ iterations.}
\end{figure}

\begin{figure}[ht]
  \centering
  \input{/home/victor/optimisation_dahu/optim_sediments/ctrl_true400.pgf}
  \caption{\label{fig:ctrl_true} Evolution of the cost function and
    the squared norm of the gradient}
\end{figure}
By comparing the result of the
optimization~\cref{fig:optimization_map_399} with the sediments
charts~\cref{fig:sediments_reduced} and the bathymetry
map~\cref{fig:depth_maps}, we can have a first overview on which
regions of the domain are properly estimated (\emph{i.e.} where the
the estimation is close to the truth value).

On a first look, we can see that the abyssal plain (the deep region
off the Bay of Biscay) remains mostly unaffected by the optimisation,
while the continental shelf, except for some parts of the English
Channel, is well retrieved.

\begin{figure}[ht]
  \centering
  \includegraphics{\imgpath optimisation_type_sediments.pdf}
  \caption[Final values of the optimisation procedure, based on the sediment type]{\label{fig:optimisation_type_sediments} Results of the
    optimisation procedure, depending on the type of sediments. The
    initial value is \SI{5e-3}{\meter}}
\end{figure}

On~\cref{fig:optimisation_type_sediments}, we can see that indeed,
points of the mesh corresponding to sand, \emph{i.e.} most of the
continental shelf, tends to get closer to the truth value $\zob$.  For
silts and muds however, the procedure did not change significantly
their roughness, and thus stays close to the initial value. This can
be probably explained by the great depth at which those sediments lay,
and thus it mitigates their influence on the drag coefficient
per~\cref{eq:quadratic_friction_vonkarman}. In the English Channel,
the size of the pebbles is quite well retrieved albeit a bit
underestimated, but the points mapped to gravel do seem to compensate:
on the northern part of the channel the size of the gravel is
overestimated, while it is underestimated on the southern part.
Finally the rocks appear to be hard to estimate properly: only about
3\% of the domain is listed as rocks, and their corresponding $\zob$
is quite large in contrast to the other sediments.

This optimisation showed that all the regions are not crucial for a
significant reduction of the values of the objective function.
We are now going to study the influence of the different inputs of the
objective function. More specifically, we are going to quantify the
influence of each region defined by its sediment type, and quantify
the influence of the uncertainties define
in~\cref{ssec:tidal_modelling} on the output of the objective
function, by means of sensitivity analysis.


\section{Sensitivity analysis of the objective function}
\label{sec:sensitivity-analysis}
Sensitivity analysis (often abbreviated as \emph{SA}), aims at
quantifying the effect of the variation of some input variable to the
output of the model~\cite{iooss_revue_2011,janon_analyse_2012}.
Intuitively, a \emph{SA} aims at understanding how much the variations
of each input or combinations of inputs explain the variations of the
output.

It can then be approached at two different scales:
around a nominal value, using the gradient, and at a global scale, by
considering the inputs as random variable, and by measuring the
variance of the output. In this work, we are going to focus
exclusively on global sensitivity analysis.

Here, sensitivity analysis is performed as a dimension reduction
method, because it will be used to reduce the input space, based on
prior assumption that the friction $\zob$ is considered constant for
each regions. Indeed, we will make the link between \emph{sensitivity}
and \emph{identifiability}~\cite{dobre_global_2010}, as
non-sensitivity implies non-identifiability. In other words, if a
parameter shows a very small influence on the output of the objective
function, any choice for its value will yield sensibly the same output
of the objective, provided that the other input parameters are the
same.


% \subsection{Methods of Sensitivity analysis}
% \label{sec:methods_SA}
% \subsubsection{Local sensitivity analysis}
% \label{sec:loca_SA} Local sensitivity
% analysis~\cite{morio_global_2011} refers to the study of how a small
% perturbation $\delta \kk$ of a nominal value $\kk$ affects the output
% of the numerical model. As we assume that the numerical model is
% accessible through the cost function $J$, a straightforward way to
% quantify this perturbation is to consider the partial derivative of
% $J$, with respect to each component of the control variable
% $\kk=(\kk_1,\dots,\kk_p)$:
% \begin{equation} \frac{\partial J}{\partial \kk_i}(\kk)
% \end{equation} The normalized local sensitivity
% at $\kk$ associated with the $i$-th component is then
% \begin{equation} \frac{{\Delta J}/{J}}{{\Delta
%       \kk_i}/{\kk_i}} = \frac{\kk_i}{J(\kk)} \frac{\partial J}{\partial\kk_i}
% \end{equation}

\subsection{Global Sensitivity Analysis: Sobol' indices}
\label{sec:sobol-indices}
As global SA calls for a probabilistic framework, we are going to
consider a real-valued random vector $X=(X_1,\cdots X_p)$ whose
components are independent, which represents the inputs of a real
function $f: \mathbb{R}^p\rightarrow \mathbb{R}$. As $X$ is a random
vector, we can introduce $Y$, the real-valued random variable defined
as $Y=f(X)$.

 % \cite{iooss_revue_2011,gilquin_echantillonnages_2016,janon_analyse_2012}
The $i$-th Sobol' indice of order $1$ is defined
as~\cite{sobol_sensitivity_1993,sobol_global_2001}
\begin{equation}
  S_i = \frac{\Var_{X_i}\left[\Ex_{Y}\left[Y \mid X_i\right]\right]}{\Var_{Y}\left[Y\right]}
\end{equation}
and can be interpreted as the fraction of the variance of the output
$Y$ explained by the variation of $X_i$ \emph{alone}. Indices of
order $2$ are defined as
\begin{equation}
  S_{i\times j} = \frac{\Var_{X_i, X_j}\left[\Ex_{Y}\left[Y \mid X_i, X_j\right]\right]}{\Var_{Y}\left[Y\right]} - S_i -S_j
\end{equation}
and account for the interactions of the inputs labelled $i$ and $j$.
Higher-order Sobol' indices can then be defined
sequentially. Total-effect indices are also central in global
sensitivity analysis: those indices measure the contributions of a
single input $X_i$ through all its possible interactions,
\textit{i.e.} by considering the effect of its own variability (as the
order $1$) and the effect of all its interactions (order $2$ and
above). Those total effect indices can be expressed as
\begin{equation}
  S_{T_i} = 1 - \frac{\Var_{X_{-i}}\left[\Ex_{Y}\left[Y \mid X_{-i}\right]\right]}{\Var_{Y}\left[Y\right]}
\end{equation}
where $X_{-i} = (X_1,\dots X_{i-1},X_{i+1},\dots,X_p)$ is random vector of $p-1$ components.

In our study, the Sobol' indices of order $1$, $2$ and total effect
are computed using a replicated
method~\cite{gilquin_making_2019,gilquin_echantillonnages_2016},
allowing for bootstrap confidence intervals for the first and second
order effects.

\subsection{SA of the objective function for the calibration of CROCO}
\subsubsection{SA on the regions defined by the sediments}
The drag coefficient, which affects the ocean circulation, is the
result of two factors as shown
in~\cref{eq:quadratic_friction_vonkarman}: the bottom roughness
$\zob$ and the ocean depth $H$.

We are first going to perform a sensitivity analysis in order to
quantify the role of each sediment-based \emph{region}, without
incorporating the knowledge on the typical size of the sediment there.
Considering the similar expected size of silts (Si) and muds particles
(V) in~\cref{tab:size_sediments}, and the limited amount of silts,
they are considered together, with the code $\mathrm{Si,V}$.
The function which will be analyzed is the one defined
\cref{eq:cost_fun_definition}:
\begin{equation}
\kk \mapsto \|\mathcal{M}(\kk, \uu^{\mathrm{truth}}) - y \|_2^2
\end{equation}
with
\begin{equation}
  \kk = (\kk_{\mathrm{R}},\kk_{\mathrm{C}},\kk_{\mathrm{G}},\kk_{\mathrm{S}},
  \kk_{\mathrm{SF}},\kk_{\mathrm{Si,V}})\in\Kspace, \text{ with }
  \Kspace = \interval{\kk_{\min}}{\kk_{\max}}^6
\end{equation}

The first, second and total order effect are
displayed~\cref{fig:SA_sediments}, where the regions defined by each
sediment is \cref{fig:sediments_reduced}. The experimental design used
here is comprised of \num{7888} points.

\label{ssec:SA_sediments}
\begin{figure}[ht]
  \centering
  \input{\imgpath SA_sediments.pgf}
  \caption{\label{fig:SA_sediments} Global SA on the regions defined by the sediment type, and bootstrap confidence intervals}
\end{figure}

We can see that the most influential region is the one defined by the
pebbles (with code C). More generally, except for the rocks, we can
see that the shallower the region, the larger impact it has on the
objective function. 


\subsubsection{SA on the tide components}
\label{ssec:SA_tide}
As introduced~\cref{ssec:tidal_modelling}, \CROCO{} incorporates
different tides constituents and we performed a sensitivity analysis
on the variable which controls the perturbation of their amplitude, as
defined in~\cref{eq:tide_error}. The SA is performed on the objective function, whose control parameter $\kk$ is set to its truth value:
\begin{equation}
  \uu \mapsto  \| \mathcal{M}(\kk^{\mathrm{truth}}, \uu) - y \|_2^2
\end{equation}
for $\uu = (\uu_1,\cdots,\uu_5)$, and $\Uspace = \interval{0}{1}^5$

\Cref{fig:SA_tides} shows the Sobol indices of order 1 (left), 2
(right), and the total effect indices, along with bootstrap confidence
intervals.
\begin{figure}[ht]
  \centering
  \input{\imgpath SA_tides.pgf}
  \caption{\label{fig:SA_tides} Global SA on the different components
    of the tide, and boostrap confidence intervals}
\end{figure}

We can see that the component of the vector affecting the amplitude of
the $M_2$ component of the tide has the most impact on the cost
function, and the $S_2$ component seems to have a non negligible
effect as well. For the other tide constituents, the SA reveals that
perturbating their amplitude has little to no-effect in this
configuration, and thus those variable will be discarded in further
analysis. The uncertain variable can then be redefined as
\begin{align}
  \UU = (\UU_1, \UU_2)%  \\
  % \UU_1 \text{ and } \UU_2 \text{i.i.d.} \\
  % \UU_i \sim \mathcal{U}\left(\interval{0}{1}\right) \text{ i=1,2}\\
\end{align}

where $\UU_1$ is the error on the $M_2$ amplitude, and $\UU_2$ is the
error on the $S_2$ amplitude, $\UU_1$ and $\UU_2$ are independent and
identically distributed, and
$\UU \sim \mathcal{U}\left(\Uspace\right)$ with
$\Uspace = \interval{0}{1}^2$.

\section{Robust Calibration of the bottom friction}

\subsection{Objective function definition}

Based on the sensitivity analysis carried in the previous section, we
are going to consider the following setting for robust calibration.
The control variable is defined as
\begin{equation}
  \kk=\left(\kk_1,\kk_2,\kk_3\right) \in \Kspace, \quad \kk_i = \log(\zob^i), \quad \KK \in \Kspace = \interval{\kk_{\min}}{\kk_{\max}}^3
\end{equation}
\todo{to check}
  where the index $1$ is for the region defined as Pebbles, the index
  $2$ is for the regions defined as Rocks, Gravel, and Sand, and the
  index $3$ is for the Silts, Mud, and Fine Sands.  Following the SA
  on the tide constituents, the uncertain variable is defined we are
  going to consider is
\begin{equation}
  \UU = (\UU_1,\UU_2), \quad \UU_i \sim \mathcal{U}(\interval{0}{1}) \text{ for } i=1,2
\end{equation}
The numerical model is defined as previously as
\begin{equation}
  \begin{array}{rcl}
    \mathcal{M}: \Kspace \times \Uspace &\longrightarrow& \mathbb{R}^{N_{\mathrm{obs}}} \\
    (\kk, \uu)& \longmapsto & \mathcal{M}(\kk, \uu) = \left(\eta_{i,t}(\kk, \uu)\right)_{\substack{1 \leq i \leq N_{\mathrm{mesh}} \\ 1 \leq t \leq N_{\mathrm{time}}}} \\ 
  \end{array}
\end{equation}
and the cost function is defined as
\begin{equation}
  \begin{array}{rcl}
    J: \Kspace \times \Uspace & \longrightarrow & \mathbb{R} \\
    (\kk, \uu) & \longmapsto & \|\mathcal{M}(\kk, \uu) - y \|^2_2
  \end{array}
\end{equation}





We also optimised the original function $J$ over
$\Kspace\times\Uspace$:
\begin{equation}
  \min_{(\kk,\uu) \in \Kspace \times \Uspace} J(\kk, \uu) = \num{29.749}
\end{equation}
for
\begin{align}
  \kk &= (\num[round-mode=places,round-precision=4]{-3.5161661} , \num[round-mode=places,round-precision=4]{-5.07764701}, \num[round-mode=places,round-precision=4]{-6.34588442}) \\\uu&= (\num[round-mode=places,round-precision=4]{0.6347829},\num[round-mode=places,round-precision=4]{0.29890637})
\end{align}
\begin{table}[!h]
  \centering
  \begin{tabular}{rrrr}\toprule
   Component & $\kk^{\mathrm{truth}}$ &Component & $\hat{\kk}_{\mathrm{opt}}$\\ \midrule
    $\kk_{\mathrm{C}}$  & \num[round-mode=places,round-precision=4]{-3.68887} & $\kk_1$ & \num[round-mode=places,round-precision=4]{-3.5161661} \\
    $\kk_{\mathrm{G}}$  & \num[round-mode=places,round-precision=4]{-4.96184} & $\kk_2$ & \num[round-mode=places,round-precision=4]{-5.07764701} \\
    $\kk_{\mathrm{R}}$  & \num[round-mode=places,round-precision=4]{-2.99573} & \multirow{4}{*}{$\kk_3$} & \multirow{4}{*}{\num[round-mode=places,round-precision=4]{-6.34588442}}\\
    $\kk_{\mathrm{S}}$  & \num[round-mode=places,round-precision=4]{-6.907755} & &\\
    $\kk_{\mathrm{SF}}$ &\num[round-mode=places,round-precision=4]{-8.804875} & &\\
    $\kk_{\mathrm{Si,V}}$&\num[round-mode=places,round-precision=4]{-10.81977} &  &\\ \bottomrule
  \end{tabular}
\end{table}
% \begin{table}[!h]
%   \centering
%   \begin{tabular}{rrr} \toprule
%     Indice & Sediment & Code  \\ \midrule
%     $1$ & Rocks & R \\
%     $2$ & Pebbles & C \\
%     $3$ & Gravel & G \\
%     $4$ & Sand & S \\
%     $5$ & Fine sand & SF \\
%     $6$ & Silts and mud & Si,V \\ \bottomrule
%   \end{tabular}
% \end{table}
    %     \label{ssec:croco_construction_gp}

In order to construct GP, we will first define the initial design: we
will sample a Latin Hypersquare on $\Kspace \times \Uspace$ in order
to construct first a GP that can be used as a surrogate. Using similar
notation as in the previous chapter, we denote $\mathcal{X}_0$ the
initial design, and $Z$ the Gaussian Process constructed and fitted
using $\mathcal{X}_0$.  We will write
\begin{equation}
  Z \sim \GP\left(m_Z, C_Z\right)
\end{equation}
with $C_Z((\kk, \uu),(\kk, \uu)) = \sigma^2_Z(\kk, \uu)$. We have for
any $(\kk, \uu) \in \Kspace\times\Uspace$,
\begin{equation}
  Z(\kk, \uu) \sim \mathcal{N}\left(m_Z(\kk, \uu), \sigma^2_Z(\kk, \uu)\right)
\end{equation}


By definition, for any $\kk\in \Kspace$ and any $\uu \in \Uspace$, we
have $J(\kk, \uu) \geq 0$.  However, this positivity property is not
necessarily verified by the surrogate $m_Z$, and thus the notion of
relative-regret is not defined. We have to first ensure that the GP
$Z$ (and consequently $Z^*$) is positive with large enough
probability.  To do so, we are first going to enrich the design near
the conditional minimisers, using the PEI criterion.  Alternatively,
one could have added points to the design according to the reliability
index, defined~\cref{eq:reliability_rho}, and thus look to find points
which have the largest probability of being negative.

\subsection{Global minimum, Conditional minimums and conditional minimisers}
\label{ssec:croco_cond_minimum_minimisers}


In the previous chapter, we defined the conditional minimum as the
minimum of the objective function given $\uu\in \Uspace$:
\begin{equation}
  J^* : \uu \mapsto J^*(\uu) = \min_{\kk\in\Kspace} J(\kk, \uu)
\end{equation}
and the conditional minimiser function as
\begin{equation}
  \kk^*:\uu  \mapsto \kk^*(\uu) = \argmin_{\kk \in \Kspace} J(\kk, \uu)
\end{equation}
Since both of these functions require an optimisation of the objective
function, they are quite expensive to compute. We can use the
surrogate in order to approximate them:
\begin{align}
  m_{Z^*}: \uu\in\Uspace \mapsto &\min_{\kk \in \Kspace} m_Z(\kk, \uu) \\
  \kk^*_{Z}: \uu \in \Uspace \mapsto &\argmin_{\kk \in \Kspace} m_{Z^*}(\uu)
\end{align}
In order to improve the accuracy of those two functions, we are first
going to enrich the design using the PEI criterion, as detailed
\cref{sec:PEI_criterion} on \cpageref{sec:PEI_criterion},
from~\cite{ginsbourger_bayesian_2014}.

The fitted GP $Z$, conditioned on the initial design $\mathcal{X}_0$
and the additional evaluations due to the PEI criterion is then used
in order to construct $m_{Z^*}$ and $\kk^*_Z$. This new design will be
denoted as $\mathcal{X}_0$. By sampling $\uu_i$ from
$\UU$ for $1\leq i \leq N_{\mathrm{samples}}$, we can then estimate
the distribution of the random variable $\kk^*(\UU)$. The samples
$\kk^*_Z(\uu_i)$ for $1\leq i \leq N_{\mathrm{samples}}$ are displayed
in~\cref{fig:distrib_minimizers_reduced}. Those estimated marginal
distributions are bimodal, and we can notice two different points
$\hat{\kk}_1=(-7, -3, -5)$, and $\hat{\kk}_2=(-5, -4, -10)$.
\begin{figure}[ht]
  \centering
  \includegraphics{\imgpath distribution_minimizers_reduced.pdf}
  \caption{\label{fig:distrib_minimizers_reduced} Estimated marginal
    distributions of the conditional minimisers $\{\kk^*_Z(\uu_i)\}_i$
    using KDE. The $y$-axis is the corresponding value of the minimum
    $m_Z^*(\uu_i)$}
\end{figure}
\todo{refaire figure} 
% Using the GP $Z\mid \mathcal{X}_0^{\mathrm{PEI}}$, we can have a first
% approximation of the repartition of the minimisers.
\todo{transition minimiseurs à regrets based}
% \begin{table}[!ht]
%   \centering
%   \begin{tabular}{rcl} \toprule
%     $p$ & $\alpha_p$ & $\kk_{\mathrm{RR},p}$ \\ \midrule
%     \num{0.5} & \num{1.027% 9807270764623
%                 } &   \\
%     \num{0.7} & \num{1.054% 1171507139304
%                 } &  \\
%     \num{0.8} & \num{1.101% 1858035465198
%                 } & \\
%     \num{0.9} & \num{1.109% 897062278107
%                 } & \\
%     \num{0.95}& \num{1.159% 8372511190105
%                 } & \\
%     \num{0.99}& \num{1.198% 4792983910981
%                 } & \\
%     \num{1.0} & \num{1.200% 6928687163256
%                 } & \\ \bottomrule
%   \end{tabular}
%   \caption{Initial}
%   \label{tab:initial_quantiles}
% \end{table}

\subsection{Relative-regret based estimators}
We are going to estimate a member of the family of relative-regret
estimators, as defined~\cref{def:RR_family}, on
\cpageref{def:RR_family}, for a specific $\alpha\geq 1$.
\begin{equation}
  \kk_{\mathrm{RR},\alpha} = \argmax_{\kk\in\Kspace} \Gamma_{\alpha}(\kk) = \argmax_{\kk \in \Kspace} \Prob_{\UU}\left[J(\kk, \UU) \leq \alpha J^*(\UU)\right]
\end{equation}

\subsubsection{Optimisation of the probability of exceeding a threshold}

We will first look to improve the estimation of $\Gamma_{\alpha}$,
defined as the following probability:
\begin{equation}
  \Gamma_{\alpha}(\kk) = \Prob_{\UU}\left[J(\kk,\UU) \leq \alpha J^*(\UU)\right]
\end{equation}
This function is the probability at which the objective function stays
below $\alpha$ times its minimal attainable value.

We are going to use a plug-in approach (see~\cref{def:plugin}) in
order to approximate the probability $\Gamma_{\alpha}$. As defined
in~\cref{eq:def_hatgamma_PI}, given the GP $Z$, constructed upon
evaluations of $J$, and a set $\{\uu_i\}_{1\leq i\leq n_{\uu}}$ of
i.i.d.\ samples from $\UU$, the plug-in approximation of
$\Gamma_{\alpha}$ is
\begin{align}
  \hat{\Gamma}^{\mathrm{PI}}_{\alpha}(\kk) &= \frac{1}{n_\uu}\sum_{i=0}^{n_{\uu}} \mathbbm{1}_{\{m_Z(\kk, \uu_i) \leq \alpha m_{Z^*}(\uu_i)\}} \\
                                           &= \frac{1}{n_\uu}\sum_{i=0}^{n_{\uu}} \mathbbm{1}_{\{m_{\Delta_{\alpha}}(\kk,\uu_i) \leq 0\}}
\end{align}
where
$\Delta_{\alpha} = Z - \alpha Z^* \sim \GP(m_{\Delta_{\alpha}},
C_{\Delta_\alpha})$ is a GP, as defined in the previous chapter. We
define the prediction variance, or mean square error, as
$\sigma^2_{\Delta_{\alpha}}: (\kk, \uu) \mapsto
C_{\Delta_{\alpha}}\big((\kk, \uu), (\kk, \uu) \big)$.

\paragraph{Stepwise reduction of the augmented IMSE}
We are going to reduce the augmented IMSE of the random process
defined as The $\mathrm{IMSE}$ associated with the GP
$\Delta_{\alpha}=Z-\alpha Z^*$ constructed using the design
$\mathcal{X}_n$ is defined as
\begin{equation}
  \IMSE(\mathcal{X}) = \int_{\Kspace \times \Uspace} \sigma^2_{\Delta_{\alpha}}(x) \,\mathrm{d}x
\end{equation}
and we select a new point to evaluate as:
\begin{equation}
  (\kk_{n+1}, \uu_{n+1}) = \argmin_{(\kk,\uu)\in\Kspace\times \Uspace} \Ex_{Z(\kk, \uu)}\left[\IMSE(\mathcal{X}_n \cup \left((\kk, \uu), Z(\kk, \uu)\right))\right]
\end{equation}

\paragraph{Sampling in the margin of uncertainty}
In the previous chapter, we defined the probability of coverage of the
random set $\{\Delta_\alpha \leq 0\}$ to be
\begin{equation}
  \pi_{\alpha}(\kk, \uu) = \Phi\left(-\frac{m_{\Delta_{\alpha}}(\kk, \uu)}{\sigma_{\Delta_\alpha}(\kk, \uu)}\right)
  \end{equation}
  and the margin of uncertainty at the level $\eta$ to be $\mathbb{M}_{\eta}$:
  \begin{equation}
    \mathbb{M}_{\eta} = \left\{(\kk, \uu)\in \Kspace \times \Uspace \mid \frac{\eta}{2} \leq \pi_{\alpha}(\kk, \uu) \leq 1-\frac{\eta}{2}\right\}
  \end{equation}
  We can then sample points in this margin, find $K$ centroids that
  represent statistically those samples, and adjust them in order to
  reduce the most the uncertainty, as explained
  in~\cref{alg:sampling_enrichment_star}.  As the margin
  $\mathbb{M}_{\eta}$ becomes thinner and thinner when adding points
  to the design (as it is easier to classify points either \emph{in}
  or \emph{out} of $\{\Delta_{\alpha} \leq 0\}$), the sampling step can
  become difficult,\todo{finir}
\subsubsection{Optimisation of the quantile of the relative-regret}

Alternatively, we want 
We will then look to optimise the quantile of order $p=0.95$ of the ratio defined as
\begin{equation}
  {\kk}_{\mathrm{RR},\alpha_p} = \argmax_{\kk \in \Kspace} \Gamma_{\alpha_p}\left(\kk\right)
\end{equation}
\begin{equation}
\max_{\kk\in\Kspace}  \Gamma_{\alpha_p}\left(\kk\right) = \Gamma_{\alpha_p}(\kk_{\mathrm{RR}, \alpha_p}) = p
\end{equation}
In \cref{chap:adaptative_design_gp}, we defined the quantile function of the ratio, at the order $p$:
\begin{equation}
  q_p(\kk) = Q_{\UU}\left(\mathrm{RR}(\kk, \UU);p \right)
\end{equation}
where $\mathrm{RR}(\kk, \UU)=\frac{J(\kk, \UU)}{J^*(\UU)}$ is the
relative-regret, that we introduce for notational convenience.
As $\mathrm{RR}$ is unknown directly, we will apply the plug-in approach, and define
\begin{equation}
  \mathrm{RR}^{\mathrm{PI}}(\kk, \uu) = \exp\left[m_{\Xi}(\kk, \uu) + \frac{1}{2}\sigma^2_{\Xi}(\kk, \uu)\right]
\end{equation}
where $\Xi$ is the lognormal approximation as defined in~\cref{eq:log_ratio}, \cpageref{eq:log_ratio}. The estimation is done using a set of i.i.d.\ samples of $\UU$: $\{\uu_i\}_{1\leq i \leq n_{\uu}}$
\begin{equation}
  \hat{q}_p^{\mathrm{PI}}(\kk) = {\mathrm{RR}}^{\mathrm{PI}}(\kk, \uu)_{(\left[n_{\uu}p\right])}
\end{equation}
where the subscript indicates the order statistic, \emph{i.e.} the $\left[n_{\uu}p\right]$ smallest value of $\mathrm{RR}^\mathrm{PI}(\kk,\uu_i)$ (with $[\cdot]$ as the rounding operator).
\todo{!!}
\section{Partial conclusion}
In this chapter, we addressed the problem of calibration of the
numerical model CROCO. After having defined the calibration and
environmental parameters, we \todo{!!}
% \begin{figure}[ht]
%   \centering
%   \input{\imgpath SA_croco.pgf}
%   \caption{\label{fig:sobol_indices} Sobol indices obtained using replicated methods and bootstrap CI}
% \end{figure}

% \begin{figure}[ht]
%   \centering
%   \input{\imgpath distribution_minimizers.pgf}
%   \caption{\label{fig:dist_minimizers} Distribution of the minimizers, estimated using the GP constructed on $J$, and enriched using the PEI criterion}
% \end{figure}

\etoile
\vfill



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfileLocal{
	\pagestyle{empty}
	\bibliographystyle{alpha}
	\bibliography{../../Bibliography}
}
\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Main_ManuscritThese"
%%% End:
