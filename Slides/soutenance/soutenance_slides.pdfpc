[duration]
45
[last_minutes]
5
[notes]
### 1
Hello everyone, my name is Victor Trappler, I'm a PhD student in the AIRSEA team in Grenoble, under the supervision of Élise Arnaud, Arthur Vidard and Laurent Debreu. \par I'm here to present some of the work entitled ``Parameter Control in the Presence of uncertainties'' 
### 2
During the whole process of the modelling of a physical system, that is from the observation of a natural phenomenon, to the simulation using numerical methods, we introduce uncertainties. Those uncertainties take the form of errors introduced by the simplifications, discretizations and parametrizations needed to represent things numerically. \par In the end, we have a set of parameters, that we need to calibrate, but during this phase of calibration, how can we be sure that we try to act only the error due to the parametrization, and are not compensating errors coming from others sources.
### 3
We are first going to see the general setting of calibration problems, and then how to define robustness in this context. Finally, we are going to see how to tackle this problem in practice using surrogate models 
### 4
In quite a classical setting, we assume that we have a model M, that takes two inputs: Θ the control variable, that we aim at calibrating, and u some environmental variables, that we consider fixed and knowns. We wish to calibrate the model wrt to some observations yobs 
### 5
 In practice, we select a likely value of the environmental parameters u, and Using the least square approach, we define J, a cost function, as the sum of the squares of the difference between the observations and the output of the numerical model. \par \par This is a deterministic optimisation problem, that we can solve using classical methods such as adjoint gradient. \par But what if the u we chose is not quite the same as the one of the observations. The minimisation procedure is supposed to correct the error on theta but will it try to compensate too much ? 
### 6
 In order to have an idea of such parameters, the case study for us is the estimation of the bottom friction. The bottom friction theta has an influence on the oceanic circulation, as it dissipates some energy by turbulences and it depends on the type of soil, and on the characteristic length of the asperities. Something that is hard to observe directly. The environmental variable u parametrizes the BC, for instance the relative amplitude of tidal components. 
### 7
 We evoked earlier that the uncertainty on theta or on u is not the same, and we can make a rough distinction between two types: \par - First, the epistemic uncertainties that result from a lack of knowledge, but can be reduced. An example is the uncertainty during the estimation of the mean value. The more samples you take, the less uncertainty there is on your estimation \par - Secondly, there is the aleatoric uncertainty, that comes from the inherent variability of the system studied. Think of the different values that a random variable takes. \par Our goal, is then to be able to reduce the epistemic uncertainty on the value of theta, while taking into account the aleatoric uncertainty. 
### 8
 As hinted before, we are going to model the aleatoric uncertainty on u by a random variable. The output of the model becomes a random variable 
### 8
 As hinted before, we are going to model the aleatoric uncertainty on u by a random variable. The output of the model becomes a random variable 
### 9
 In our study, the model is completely deterministic, so we can control its inputs The cost function, becomes then a function of two theta and u. We still wish to minimise with respect to theta, but what can we do for u ? 
### 10
 To have a first look at the problem of misspecification, we try to calibrate the bottom friction on this domain in a twin experiment setup, with or without misspecification. This figures shows the truth value of the bottom friction. \par \par When optimizing without misspecification, we can see that the region of the english channel is able to retrieve the truth value, while the regions farther from the coast, in the bay of biscay, stay quite unaffected by the procedure. So far so good. \par When we introduce a 1\% error in the amplitude of the M2 tide, we can see more variations, especially in the english channel, as it compensate the misspecification of the tide. \par The estimation of theta is sensitive to the value of the environmental parameter. So the question that arise is ``how to get a value of theta, which shows robust properties when the environmental parameter varies ?'' 
### 10
 To have a first look at the problem of misspecification, we try to calibrate the bottom friction on this domain in a twin experiment setup, with or without misspecification. This figures shows the truth value of the bottom friction. \par \par When optimizing without misspecification, we can see that the region of the english channel is able to retrieve the truth value, while the regions farther from the coast, in the bay of biscay, stay quite unaffected by the procedure. So far so good. \par When we introduce a 1\% error in the amplitude of the M2 tide, we can see more variations, especially in the english channel, as it compensate the misspecification of the tide. \par The estimation of theta is sensitive to the value of the environmental parameter. So the question that arise is ``how to get a value of theta, which shows robust properties when the environmental parameter varies ?'' 
### 10
 To have a first look at the problem of misspecification, we try to calibrate the bottom friction on this domain in a twin experiment setup, with or without misspecification. This figures shows the truth value of the bottom friction. \par \par When optimizing without misspecification, we can see that the region of the english channel is able to retrieve the truth value, while the regions farther from the coast, in the bay of biscay, stay quite unaffected by the procedure. So far so good. \par When we introduce a 1\% error in the amplitude of the M2 tide, we can see more variations, especially in the english channel, as it compensate the misspecification of the tide. \par The estimation of theta is sensitive to the value of the environmental parameter. So the question that arise is ``how to get a value of theta, which shows robust properties when the environmental parameter varies ?'' 
### 10
 To have a first look at the problem of misspecification, we try to calibrate the bottom friction on this domain in a twin experiment setup, with or without misspecification. This figures shows the truth value of the bottom friction. \par \par When optimizing without misspecification, we can see that the region of the english channel is able to retrieve the truth value, while the regions farther from the coast, in the bay of biscay, stay quite unaffected by the procedure. So far so good. \par When we introduce a 1\% error in the amplitude of the M2 tide, we can see more variations, especially in the english channel, as it compensate the misspecification of the tide. \par The estimation of theta is sensitive to the value of the environmental parameter. So the question that arise is ``how to get a value of theta, which shows robust properties when the environmental parameter varies ?'' 
### 11
 So that is how we define robustness in this work: So basically, we have two main objectives: - First to find some criteria of robustness to estimate theta - Be able to compute those estimates quickly 
### 12
 I'm going to present very quickly some estimates that can be considered robust, but will focus mainly on the last one. First we can think about minimising in the worst case sense. This usually leads to overly conservative estimates as we are maximizing over the whole space U. We can also think about minimising the moments, such as the mean or the variance, or even combine them in a multiobjective setting by looking for the pareto front. \par \par Every choice of environmental variable gives a distinct situation The aspect we are going to focus on is based on the regret, so it implies a comparison with the best performance attainable for each u. 
### 13
 The main idea is that we want to consider individually all situations induced by the value of the environmental variable. Basically, once a value u is sampled, the problem is deterministic, so under some assumption, we have a minimiser theta star that is a function of u \par \par Keeping in mind the random nature of U, we can define the random variable thetastar, and its density (if it is defined), can be seen as the frequency of which a value theta is optimal. \par \par That is an interesting information, but we can have a little more than that. We may want to include theta that yield values of the cost function close to a minimum. To do that, we introduce a relaxation of the equality constraint with alpha, so that for a given u, we consider acceptable the theta that give values of the cost function between Jstar, the optimal value and alpha times Jstar So finally, we compute the probability that this given theta is acceptable with respect to the level alpha 
### 13
 The main idea is that we want to consider individually all situations induced by the value of the environmental variable. Basically, once a value u is sampled, the problem is deterministic, so under some assumption, we have a minimiser theta star that is a function of u \par \par Keeping in mind the random nature of U, we can define the random variable thetastar, and its density (if it is defined), can be seen as the frequency of which a value theta is optimal. \par \par That is an interesting information, but we can have a little more than that. We may want to include theta that yield values of the cost function close to a minimum. To do that, we introduce a relaxation of the equality constraint with alpha, so that for a given u, we consider acceptable the theta that give values of the cost function between Jstar, the optimal value and alpha times Jstar So finally, we compute the probability that this given theta is acceptable with respect to the level alpha 
### 13
 The main idea is that we want to consider individually all situations induced by the value of the environmental variable. Basically, once a value u is sampled, the problem is deterministic, so under some assumption, we have a minimiser theta star that is a function of u \par \par Keeping in mind the random nature of U, we can define the random variable thetastar, and its density (if it is defined), can be seen as the frequency of which a value theta is optimal. \par \par That is an interesting information, but we can have a little more than that. We may want to include theta that yield values of the cost function close to a minimum. To do that, we introduce a relaxation of the equality constraint with alpha, so that for a given u, we consider acceptable the theta that give values of the cost function between Jstar, the optimal value and alpha times Jstar So finally, we compute the probability that this given theta is acceptable with respect to the level alpha 
### 14
 What does it look like on a concrete example. We have the plot of a cost function, where theta is the x axis, and u is on the y axis. \par As said earlier, for each horizontal cross section, so for u fixed, we compute the minimiser, theta star of u. \par We can then compute the whole set of the conditional minimisers \par Now, we set alpha: inside the yellow lines, we are between the minimum and alpha times the minimum \par Finally, we construct and measure for each theta the probability to be within this acceptable region. Great, now we just have to know how to choose alpha. 
### 14
 What does it look like on a concrete example. We have the plot of a cost function, where theta is the x axis, and u is on the y axis. \par As said earlier, for each horizontal cross section, so for u fixed, we compute the minimiser, theta star of u. \par We can then compute the whole set of the conditional minimisers \par Now, we set alpha: inside the yellow lines, we are between the minimum and alpha times the minimum \par Finally, we construct and measure for each theta the probability to be within this acceptable region. Great, now we just have to know how to choose alpha. 
### 14
 What does it look like on a concrete example. We have the plot of a cost function, where theta is the x axis, and u is on the y axis. \par As said earlier, for each horizontal cross section, so for u fixed, we compute the minimiser, theta star of u. \par We can then compute the whole set of the conditional minimisers \par Now, we set alpha: inside the yellow lines, we are between the minimum and alpha times the minimum \par Finally, we construct and measure for each theta the probability to be within this acceptable region. Great, now we just have to know how to choose alpha. 
### 14
 What does it look like on a concrete example. We have the plot of a cost function, where theta is the x axis, and u is on the y axis. \par As said earlier, for each horizontal cross section, so for u fixed, we compute the minimiser, theta star of u. \par We can then compute the whole set of the conditional minimisers \par Now, we set alpha: inside the yellow lines, we are between the minimum and alpha times the minimum \par Finally, we construct and measure for each theta the probability to be within this acceptable region. Great, now we just have to know how to choose alpha. 
### 15
Great so now we have Gamma(theta) which is the probability that theta gives a cost alpha acceptable If we have an idea of a threshold we don't want to exceed, so if alpha is known we can maximize the probability of being alpha acceptable \par Or, on the other hand, as gamma is a probability, we can look for the smallest relaxation, where the probability of acceptability reaches a certain confidence 1-eta. \par We can then define the family of relative-regret estimators, which are the maximizers of such a probability of being alpha acceptable. Depending on the approach, we can nudge toward optimal performances with small alpha, or risk adverse preference, by setting a bigger relaxation. 
### 16
we discussed so far the relative regret, that takes the form of a multiplicative relaxation. Why this over the additive regret ? \par Relative regret takes better into account the magnitude of the cost function, as the region of acceptability grows with alpha AND Jstar. When the situation is already bad, we don't want to put much effort to stay close to the minimum theta star of u. On the other hand, for Jstar close to 0, 
### 17
We now have a family of estimators, but in practice, finding them is expensive, as it requires probability estimation, and various optimisations, that is why we are going to use surrogates to tackle this problem
We choose Gaussian Process regression as a metamodel, as it can replace cheaply the computer code
### 17
We now have a family of estimators, but in practice, finding them is expensive, as it requires probability estimation, and various optimisations, that is why we are going to use surrogates to tackle this problem
We choose Gaussian Process regression as a metamodel, as it can replace cheaply the computer code
### 18
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
