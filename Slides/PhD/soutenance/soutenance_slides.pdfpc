[duration]
45
[last_minutes]
5
[notes]
### 1
Thank you for the introduction, and thank you to the jury for being here today. \par My name is Victor Trappler, and I'm going to defend my PhD, which is named ``Parameter control in the presence of uncertainties'' \par This work has been realized in the AIRSEA team, here in Grenoble, under the supervision of Ã‰lise Arnaud, Arthur Vidard and Laurent Debreu
### 2
Reality is often very complex to understand in its entirety, but at the same time, the ability to understand, and to predict our surroundings allow us to take decisions which have environmental, societal or economic impact. \par However, due to this complexity, a lot of simplifications are required in order to be able to represent mathematically natural phenomena. Those simplified versions can then be studied more precisely, and even implemented numerically, to create simulations, and provide prediction and forecasts
### 3
We are going to take for instance the modelling of the ocean. \par First thing first, most numerical models are usually based on a subdivision of the ocean into cells, which interacts with each others. Those cells have a size in the order of the kilometer. \par At the bottom of the ocean, the different types of soil and sediments have an influence on the circulation of the water at the surface. Indeed, the ocean bed is not completely smooth, there are rocks, sand, gravel, and all those asperities create turbulences, which dissipate energy. This phenomenon happens at a scale much smaller than the scale of the mesh provided for the simulation. \par All in all, instead of modelling individually each rock or asperity, we can introduce a parameter, which will quantify for each cell the effect of the friction. 
### 3
We are going to take for instance the modelling of the ocean. \par First thing first, most numerical models are usually based on a subdivision of the ocean into cells, which interacts with each others. Those cells have a size in the order of the kilometer. \par At the bottom of the ocean, the different types of soil and sediments have an influence on the circulation of the water at the surface. Indeed, the ocean bed is not completely smooth, there are rocks, sand, gravel, and all those asperities create turbulences, which dissipate energy. This phenomenon happens at a scale much smaller than the scale of the mesh provided for the simulation. \par All in all, instead of modelling individually each rock or asperity, we can introduce a parameter, which will quantify for each cell the effect of the friction. 
### 4
 To summarize, in the end, we have a model, with a lot of parameters, which is supposed to represent the reality. \par Some of those parameters cannot be chosen, as their value may come from real observations, measured physical properties, or other environmental conditions. \par Some other need to be tuned accordingly. Now, the question, is how to choose the value of those remaining parameters, so that the model, the simulations are accurate enough ? \par 
### 5
We are now going to translate these questions using a classical setting of inverse problem. \par The parameter we want to calibrate, to control is called the control parameter theta \par The other parameters, that we do not have much control are called the environmental variables, which are considered fixed, and known. \par our numerical model, M can be seen as an operator, taking as inputs theta and u, and outputs an observable quantity, for instance the sea water height. This is the direct simulation. \par Our goal, in an inverse problem setting, is, given some observations y, what is the best value of theta, so that the output of the numerical model matches as closely as possible the observations ? 
### 6
 In practice, we select a value of the environmental parameters u, and using the least square approach, we define J, an objective function, as the sum of the squares of the difference between the observations and the output of the numerical model. \par \par This is a deterministic optimisation problem, that we can solve using classical methods such as adjoint gradient. The resulting parameter theta hat is then optimal in this situation. \par However, this estimation depends on the value of the environmental parameter chosen initially. Now, what happens if this parameter changes ? The minimisation procedure is supposed to correct the error on theta but will it try to compensate too much ? 
### 6
 In practice, we select a value of the environmental parameters u, and using the least square approach, we define J, an objective function, as the sum of the squares of the difference between the observations and the output of the numerical model. \par \par This is a deterministic optimisation problem, that we can solve using classical methods such as adjoint gradient. The resulting parameter theta hat is then optimal in this situation. \par However, this estimation depends on the value of the environmental parameter chosen initially. Now, what happens if this parameter changes ? The minimisation procedure is supposed to correct the error on theta but will it try to compensate too much ? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 7
 We are going to illustrate this issue, with the calibration problem of the bottom friction in a model of the north atlantic ocean. This setting will be detailed later, but we can see how the optimal value depends on the environmental parameter: \par Some regions are left unaffected, especially in the bay of biscay, but some other vary directly with the environmental parameter. \par So now the question is, how to select a value of the control parameter, such that it is quite close to the reality, even when u changes? 
### 8
This is how we are going to define robustness: an estimate will be considered robust if the objective function gives good performances when u varies \par \par In this presentation we are going to see how this notion of robustness can be translated quantitatively, especially by introducing notions of regret. \par As we are going to see, such robust estimates can become expensive to compute. We will then introduce methods based on gaussian processes, in order to make computations tractable \par Finally, we are going to apply some of those methods to the calibration of an academic model of the ocean, based on CROCO
### 11
We evoked earlier that the uncertainty on theta or on u is not the same, and we can make a rough distinction between two types: \par - First, the epistemic uncertainties that result from a lack of knowledge, but can be reduced. An example is the uncertainty during the estimation of the mean value. The more samples you take, the less uncertainty there is on your estimation \par - Secondly, there is the aleatoric uncertainty, that comes from the inherent variability of the system studied. Think of the different values that a random variable takes. \par Our goal, is then to be able to reduce the epistemic uncertainty on the value of theta, while taking into account the aleatoric uncertainty.
### 12
The aleatoric uncertainty present in the environmental variable will be modelled using a random variable. \par The distribution of this random variable, written using an uppercase letter U is assumed to be known. The lowercase u is a sample, a realization of this random variable \par In this case, we can consider that the output of the model is a random variable. 
### 12
The aleatoric uncertainty present in the environmental variable will be modelled using a random variable. \par The distribution of this random variable, written using an uppercase letter U is assumed to be known. The lowercase u is a sample, a realization of this random variable \par In this case, we can consider that the output of the model is a random variable. 
### 13
I'd like to point out that the numerical model is still completely deterministic: the choice and sampling of lowercase u is still up to the user. \par But in terms of random variable, we will now have to consider that the objective function is a random variable, indexed by theta 
### 14
I'm going to present very quickly some estimates that can be considered robust. \par First we can think about minimising the objective function in the worst case sense. This usually leads to overly conservative estimates as we are maximizing over the whole space U. \par Due to the fact that the objective function can be considered as a random variable, we can also think about minimising the moments, such as the mean value. Or by looking for the pareto front in order to get a good compromise between mean and variance of the objective function. \par Finally, we can also look to minimize some well-chosen quantile of the objective function. \par In this presentation, we are going to focus on a specific idea, based on the regret: \par Every choice of environmental variable gives a distinct situation The aspect we are going to focus on is based on the regret, so it implies a comparison with the best performance attainable for each u. 
### 15
For each choice of u, the environmental variable, we have a different calibration problem. Once the optimisation is performed, we have an optimal value Jstar, and an estimate theta star. \par But in the end, we want a single value of theta, which is good even when u varies, so we are going to compare the performances, so the value of the objective function when theta is set to the optimal value given u, so Jstar \par So we are going to introduce the relative-regret, which is defined by ratio of the objective function, divided by the conditional minimum Jstar. So when the regret is large, there is a lot of deviations from the optimal value. \par Based on this idea, we can introduce a notion of acceptability by using a threshold, alpha. So a pair of points is considered acceptable at a level alpha, if the relative regret is less than alpha.
### 15
For each choice of u, the environmental variable, we have a different calibration problem. Once the optimisation is performed, we have an optimal value Jstar, and an estimate theta star. \par But in the end, we want a single value of theta, which is good even when u varies, so we are going to compare the performances, so the value of the objective function when theta is set to the optimal value given u, so Jstar \par So we are going to introduce the relative-regret, which is defined by ratio of the objective function, divided by the conditional minimum Jstar. So when the regret is large, there is a lot of deviations from the optimal value. \par Based on this idea, we can introduce a notion of acceptability by using a threshold, alpha. So a pair of points is considered acceptable at a level alpha, if the relative regret is less than alpha.
### 16
For an illustration purpose, we are going to see what does it look like on an analytical function J, which is strictly positive. On the x axis, we have the control parameter, on the y axis, the environmental parameter. \par So for a given u, so for an horizontal slice of this figure, we can optimize the objective function, this leads to Jstar, the conditional minimum, and theta star, the conditional minimiser. \par By doing so for all the other values of the environmental paramter, we can get visualize the set of all conditional minimisers. \par We now introduce the threshold, alpha, and define the region of alpha acceptability. So within the yellow lines, we are acceptable at a level alpha, since the objective function is less than alpha times Jstar. \par We want to see how often each single value theta is acceptable, so we are going to measure the set of acceptable value with respect to the probability distribution of U, this is the green line. \par Finally, that is how Gamma alpha is defined: this represent the probabiltiy to be acceptable at a level alpha, or in other words, the probability that the relative-regret is less than alpha. This can be seen as a measure of robustness, so we want this green line to be as long as possible. 
### 16
For an illustration purpose, we are going to see what does it look like on an analytical function J, which is strictly positive. On the x axis, we have the control parameter, on the y axis, the environmental parameter. \par So for a given u, so for an horizontal slice of this figure, we can optimize the objective function, this leads to Jstar, the conditional minimum, and theta star, the conditional minimiser. \par By doing so for all the other values of the environmental paramter, we can get visualize the set of all conditional minimisers. \par We now introduce the threshold, alpha, and define the region of alpha acceptability. So within the yellow lines, we are acceptable at a level alpha, since the objective function is less than alpha times Jstar. \par We want to see how often each single value theta is acceptable, so we are going to measure the set of acceptable value with respect to the probability distribution of U, this is the green line. \par Finally, that is how Gamma alpha is defined: this represent the probabiltiy to be acceptable at a level alpha, or in other words, the probability that the relative-regret is less than alpha. This can be seen as a measure of robustness, so we want this green line to be as long as possible. 
### 16
For an illustration purpose, we are going to see what does it look like on an analytical function J, which is strictly positive. On the x axis, we have the control parameter, on the y axis, the environmental parameter. \par So for a given u, so for an horizontal slice of this figure, we can optimize the objective function, this leads to Jstar, the conditional minimum, and theta star, the conditional minimiser. \par By doing so for all the other values of the environmental paramter, we can get visualize the set of all conditional minimisers. \par We now introduce the threshold, alpha, and define the region of alpha acceptability. So within the yellow lines, we are acceptable at a level alpha, since the objective function is less than alpha times Jstar. \par We want to see how often each single value theta is acceptable, so we are going to measure the set of acceptable value with respect to the probability distribution of U, this is the green line. \par Finally, that is how Gamma alpha is defined: this represent the probabiltiy to be acceptable at a level alpha, or in other words, the probability that the relative-regret is less than alpha. This can be seen as a measure of robustness, so we want this green line to be as long as possible. 
### 16
For an illustration purpose, we are going to see what does it look like on an analytical function J, which is strictly positive. On the x axis, we have the control parameter, on the y axis, the environmental parameter. \par So for a given u, so for an horizontal slice of this figure, we can optimize the objective function, this leads to Jstar, the conditional minimum, and theta star, the conditional minimiser. \par By doing so for all the other values of the environmental paramter, we can get visualize the set of all conditional minimisers. \par We now introduce the threshold, alpha, and define the region of alpha acceptability. So within the yellow lines, we are acceptable at a level alpha, since the objective function is less than alpha times Jstar. \par We want to see how often each single value theta is acceptable, so we are going to measure the set of acceptable value with respect to the probability distribution of U, this is the green line. \par Finally, that is how Gamma alpha is defined: this represent the probabiltiy to be acceptable at a level alpha, or in other words, the probability that the relative-regret is less than alpha. This can be seen as a measure of robustness, so we want this green line to be as long as possible. 
### 17
 This is how we can define the relative regret estimates, as maximizers of Gamma alpha, so this family is indexed by the threshold alpha. This lead to the publication of an article. \par For a member of this family, we have then some more information on its robustness: \par alpha represents the range of variation of the objective function relatively to the conditional optimum \par p, the maximal value of Gamma alpha, is the probability with which we stay within this range 
### 18
 The choice of alpha, or of p is up to the user: \par if alpha is chosen small, so close to 1, we are not allowing much deviation from the conditional minimisers, and as a consequence, the probability for being within this acceptable region is lower \par On the other hand, if we choose alpha to be large, the acceptable region is large as well, so it is easier to reach higher probabilities of being acceptable. \par The alternative is to set a target probability $p$, and to adjust the threshold alpha, so that the maximum reached is indeed p \par 
### 19
To summarize, we have two courses of action \par The first, where we choose a threshold alpha. To get an estimate, we have to maximize a probability, the probability of being alpha acceptable \par The other one, where we choose a target probability p requires to find the smallest value of alpha, such that the target is reached. So it can be considered as the minimization of a quantile of order p of a specific random variable \par As we could see the relative regret estimates require the optimization of specific statistical quantites, which can be expensive in practice
### 19
To summarize, we have two courses of action \par The first, where we choose a threshold alpha. To get an estimate, we have to maximize a probability, the probability of being alpha acceptable \par The other one, where we choose a target probability p requires to find the smallest value of alpha, such that the target is reached. So it can be considered as the minimization of a quantile of order p of a specific random variable \par As we could see the relative regret estimates require the optimization of specific statistical quantites, which can be expensive in practice
### 21
We now have a family of estimators, but in practice, finding them is expensive, as it requires probability estimation, and various optimisations, that is why we are going to use surrogates to tackle this problem
### 22
We choose Gaussian Process regression as a metamodel, as it can replace cheaply the computer code
### 22
We choose Gaussian Process regression as a metamodel, as it can replace cheaply the computer code
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
### 27
One of the first problem we encountered is the computation of the conditional minimum and minimisers. Using Gaussian processes, and an enrichment criterion called the Profile Expected Improvement, we can reconstruct the Jstar and theta star function iteratively, and then use the kriging prediction as a surrogate since Jstar is well approximated
